{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a65cae4-b60a-484b-93d7-1d142dceba68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from pdfminer.high_level import extract_pages\n",
    "from pdfminer.layout import LTTextBox, LTTextLine\n",
    "import re\n",
    "import pandas as pd\n",
    "import json\n",
    "from typing import List, Type, Literal \n",
    "from pydantic import BaseModel\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "import json\n",
    "from langchain.vectorstores import FAISS\n",
    "import os\n",
    "from glob import glob\n",
    "from IPython.display import HTML, Markdown \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4aa26b6e-9f1e-4cf2-a20f-cc2690451eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = r'C:\\Users\\Akshaya V\\git\\Earnings research\\Earnings_agent\\PublicReportResearch-main'\n",
    "full_path = os.path.join(dic, 'docs')\n",
    "question=\"Extract the net revenue of citi bank\"\n",
    "llm_model_name=\"qwen3:4b\"\n",
    "embedding_model=\"nomic-embed-text\"\n",
    "sec_excel_path=r'C:/Users/Akshaya V/git/Earnings research/Earnings_agent/PublicReportResearch-main/50_metrics.xlsx'\n",
    "sec_excel=pd.read_excel(r'C:/Users/Akshaya V/git/Earnings research/Earnings_agent/PublicReportResearch-main/50_metrics.xlsx')\n",
    "allowed_metrics: List[str] = sec_excel.columns[2:].unique().tolist()\n",
    "allowed_banks: List[str] = sec_excel['CompanyName'].unique().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa3aad2-7aa5-4963-a81f-31a528ab6184",
   "metadata": {},
   "source": [
    "**Intent of the question - Exact or vague**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f975dfce-f3d0-4579-8ac3-6f64bea7f353",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 1. Define the Pydantic Schema\n",
    "# ---------------------------\n",
    "class ParsedRequest_intent(BaseModel):\n",
    "    intent: str                 \n",
    " \n",
    "\n",
    "# ---------------------------\n",
    "# 2. Function to Use ChatOllama with Pydantic Schema\n",
    "# ---------------------------\n",
    "def intent(\n",
    "    llm_model_name: str,\n",
    "    user_input: str,\n",
    "    schema: Type[BaseModel]\n",
    "    \n",
    ") -> BaseModel:\n",
    "    system_prompt = \"\"\"You are a expert in classifying questions into 2 categories. The 2 categories are exact question , needs_clarification. A question is marked as exact if it has concrete details in 3 categories - company name, quarter & Year , metrics to be analysed. It is needs_clarification if the user uses words like analyse, in detail , research, elaborate or if the user doesn't provide specific metrics or company name or year & quarter to be analysed . give the output in JSON format srtictly . JSON has one key and it is called intent . For example ) {\"intent\": \"exact\"}\"\"\"\n",
    "    # Load the Ollama model\n",
    "    llm = ChatOllama(model=llm_model_name)\n",
    "\n",
    "    # Create and send the prompt\n",
    "    messages = [\n",
    "        SystemMessage(content=system_prompt.strip()),\n",
    "        HumanMessage(content=user_input.strip())\n",
    "    ]\n",
    "    response = llm.invoke(messages)\n",
    "    return response.content.strip()\n",
    "    # Validate using Pydantic\n",
    "    # try:\n",
    "    #     raw = response.content.strip()\n",
    "    \n",
    "    #     # Optional: clean triple backticks if LLM returns markdown\n",
    "    #     if \"```\" in raw:\n",
    "    #         import re\n",
    "    #         match = re.search(r\"```(?:json)?\\s*(\\{.*?\\})\\s*```\", raw, re.DOTALL)\n",
    "    #         if match:\n",
    "    #             raw = match.group(1)\n",
    "    \n",
    "    #     # Step 1: Convert JSON string to Python dict\n",
    "    #     parsed_dict = json.loads(raw)\n",
    "    \n",
    "    #     # Step 2: Validate and convert into a Pydantic object\n",
    "    #     parsed_model = schema.model_validate(parsed_dict)\n",
    "    \n",
    "    #     # Step 3: Return it (now it has `.model_dump_json()` etc.)\n",
    "    #     return parsed_model\n",
    "\n",
    "    # except Exception as e:\n",
    "    #     raise ValueError(f\"Failed to parse model output: {e}\\nRaw Output:\\n{response.content}\")\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "result = intent(\n",
    "    llm_model_name=llm_model_name,  # Replace with your loaded Ollama model name\n",
    "    user_input=question,\n",
    "    schema=ParsedRequest_intent\n",
    ")\n",
    "intent1 = result.split(\"</think>\")[-1].strip()\n",
    "intent=(json.loads(intent1))\n",
    "#intent=intent[\"intent\"]\n",
    "print(intent)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4735c25c-52fb-4271-b8a5-0c38f13a2ff8",
   "metadata": {},
   "source": [
    "**REPHRASING VAGUE QUESTION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ab241c-4293-4b1b-b0f7-d773702c1c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vague(model, question, allowed_banks, allowed_metrics):\n",
    "    prompt = f\"\"\"\n",
    "You are an expert in rewriting vague finance-related questions. Your sole task is to **rephrase the user's question** by **expanding it explicitly** along three dimensions:\n",
    "- Company names (banks)\n",
    "- Financial metrics\n",
    "- Quarters and Years\n",
    "\n",
    "Important:\n",
    "- DO NOT provide an answer, explanation, or rationale.\n",
    "- ONLY return the **rewritten question** in plain text.\n",
    "\n",
    "Defaults (if the user doesn’t specify):\n",
    "1. Company: Wells Fargo\n",
    "2. Quarters: 1Q2025, 4Q2024, 3Q2024\n",
    "3. Metrics: NetIncome, EarningsPerShare, TotalRevenue\n",
    "4. Add important metrics for senior leadership (e.g., ReturnOnEquity, ROA, CET1Ratio)\n",
    "\n",
    "Rules:\n",
    "- Use only official bank names from: {json.dumps(allowed_banks)}\n",
    "- Convert quarters to format: \"1Q2025\"\n",
    "- Use only metrics from: {json.dumps(allowed_metrics)}\n",
    "\n",
    "Example:\n",
    "User: Extract the net revenue of citi bank in 2025Q1  \n",
    "Output: Extract TotalRevenue, NetIncome, EarningsPerShare, and ReturnOnEquity for Citigroup Inc in 1Q2025, 4Q2024, and 3Q2024.\n",
    "\n",
    "Respond ONLY with the rewritten version of the user’s question.\n",
    "Here is the question:  {question}\n",
    "    \"\"\"\n",
    "\n",
    "    llm = ChatOllama(model=model)\n",
    "   # print(prompt)\n",
    "   \n",
    "    response = llm.invoke(prompt)\n",
    "    return response.content.strip()\n",
    "\n",
    "if (intent!=\"exact\"):\n",
    "    result = vague(\n",
    "    model=llm_model_name,  # Replace with your loaded Ollama model name\n",
    "    question=question,\n",
    "    allowed_banks=allowed_banks,\n",
    "    allowed_metrics=allowed_metrics\n",
    "    )\n",
    "    question = result.split(\"</think>\")[-1].strip()\n",
    "    print(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0422107-ecab-4ed3-ac0f-398144d79423",
   "metadata": {},
   "source": [
    "**Getting Pydantic schema inputs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd92e029-2e60-43e6-b0fa-6f0f027d7813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 1. Define the Pydantic Schema\n",
    "# ---------------------------\n",
    "class ParsedRequest(BaseModel):\n",
    "                 \n",
    "    banks: List[str]            # Must match allowed_banks\n",
    "    quarters: List[str]         # e.g., \"1Q2025\", \"4Q2024\"\n",
    "    metrics: List[str]          # Must match allowed_metrics\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# 2. Function to Use ChatOllama with Pydantic Schema\n",
    "# ---------------------------\n",
    "def parse_with_chatollama(\n",
    "        llm_model_name: str,\n",
    "        user_input: str,\n",
    "        schema: Type[BaseModel],\n",
    "        allowed_banks: List[str],\n",
    "        allowed_metrics: List[str]\n",
    "    ) -> BaseModel:\n",
    "    system_prompt = f\"\"\"\n",
    "You are a financial assistant. Your task is to extract structured information from user input and return it in the following JSON format:\n",
    "\n",
    "{{\n",
    "  \n",
    "  \"banks\": [valid bank names],\n",
    "  \"quarters\": [\"1Q2025\", \"4Q2024\", \"3Q2024\"],\n",
    "  \"metrics\": [valid metric keys]\n",
    "}}\n",
    "\n",
    "Rules:\n",
    "- Map any abbreviation or alias to official bank names from this list: {json.dumps(allowed_banks)}\n",
    "- Extract all mentioned quarters in \"1Q2025\" format. Include the previous 2 quarters for each.\n",
    "- Extract only metrics listed here: {json.dumps(allowed_metrics)}.\n",
    "- Output only the JSON structure as shown above, no explanation or markdown.\n",
    "\"\"\"\n",
    "\n",
    "    # Load the Ollama model\n",
    "    llm = ChatOllama(model=llm_model_name)\n",
    "\n",
    "    # Create and send the prompt\n",
    "    messages = [\n",
    "        SystemMessage(content=system_prompt.strip()),\n",
    "        HumanMessage(content=user_input.strip())\n",
    "    ]\n",
    "    response = llm.invoke(messages)\n",
    "    return response.content.strip()\n",
    "\n",
    "    # Validate using Pydantic\n",
    "    # try:\n",
    "    #     raw = response.content.strip()\n",
    "    \n",
    "    #     # Optional: clean triple backticks if LLM returns markdown\n",
    "    #     if \"```\" in raw:\n",
    "    #         import re\n",
    "    #         match = re.search(r\"```(?:json)?\\s*(\\{.*?\\})\\s*```\", raw, re.DOTALL)\n",
    "    #         if match:\n",
    "    #             raw = match.group(1)\n",
    "    \n",
    "    #     # Step 1: Convert JSON string to Python dict\n",
    "    #     parsed_dict = json.loads(raw)\n",
    "    \n",
    "    #     # Step 2: Validate and convert into a Pydantic object\n",
    "    #     parsed_model = schema.model_validate(parsed_dict)\n",
    "    \n",
    "   #     # Step 3: Return it (now it has `.model_dump_json()` etc.)\n",
    "    #     return parsed_model\n",
    "\n",
    "    # except Exception as e:\n",
    "    #     raise ValueError(f\"Failed to parse model output: {e}\\nRaw Output:\\n{response.content}\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3df4bda-1f90-4500-aa71-81f5d093202b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result = parse_with_chatollama(\n",
    "    llm_model_name=llm_model_name,  # Replace with your loaded Ollama model name\n",
    "    user_input=question,\n",
    "    schema=ParsedRequest,\n",
    "    allowed_banks=allowed_banks,\n",
    "    allowed_metrics=allowed_metrics\n",
    ")\n",
    "response = result.split(\"</think>\")[-1].strip()\n",
    "print(response)\n",
    "\n",
    "# response=(result.model_dump_json())\n",
    "input_params=(json.loads(response))\n",
    "print(input_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cca8dc-ae8d-452e-a8cb-184e6594f8d4",
   "metadata": {},
   "source": [
    "**PDF Reader RAG**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd79d4e-15f6-4f87-9420-6de47bc5c7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParsedRequest(BaseModel):\n",
    "    intent: str\n",
    "    banks: List[str]\n",
    "    quarters: List[str]\n",
    "    metrics: List[str]\n",
    "\n",
    "def is_natural_language(text):\n",
    "    # Must contain at least one sentence (simple heuristic)\n",
    "    return bool(re.search(r\"[A-Za-z]{4,}.*\\.\", text)) and not is_table_like(text)\n",
    "\n",
    "def is_table_like(text):\n",
    "    lines = text.strip().splitlines()\n",
    "    if len(lines) < 2:\n",
    "        return False\n",
    "\n",
    "    table_like = 0\n",
    "    for line in lines:\n",
    "        tokens = line.strip().split()\n",
    "        num_tokens = len(tokens)\n",
    "        numbers = len([t for t in tokens if re.fullmatch(r\"[\\d,.%$]+\", t)])\n",
    "        symbols = len([t for t in tokens if re.fullmatch(r\"[\\d,.%$O/(U)-]+\", t)])\n",
    "\n",
    "        if num_tokens >= 3 and numbers / num_tokens > 0.5:\n",
    "            table_like += 1\n",
    "        elif len(re.findall(r\"\\$\\s?\\d\", line)) > 1:  # multiple dollar values\n",
    "            table_like += 1\n",
    "        elif len(re.findall(r\"\\d{2,},\", line)) > 1:\n",
    "            table_like += 1\n",
    "\n",
    "    return table_like / len(lines) > 0.4\n",
    "\n",
    "def extract_text_excluding_tables(pdf_path):\n",
    "    final_text = []\n",
    "\n",
    "    for page_layout in extract_pages(pdf_path):\n",
    "        for element in page_layout:\n",
    "            if isinstance(element, (LTTextBox, LTTextLine)):\n",
    "                text = element.get_text().strip()\n",
    "                if text and is_natural_language(text):\n",
    "                    final_text.append(text)\n",
    "\n",
    "    return \"\\n\\n\".join(final_text).strip()\n",
    "\n",
    "def parse_filename_metadata(filename: str):\n",
    "    name = os.path.splitext(os.path.basename(filename))[0]\n",
    "    parts = name.split(\"_\")\n",
    "    bank_map = {\n",
    "        \"jpm\": \"JP Morgan Chase\",\n",
    "        \"boa\": \"Bank of America\",\n",
    "        \"citi\": \"Citigroup\",\n",
    "        \"gs\": \"Goldman Sachs\",\n",
    "        \"ms\": \"Morgan Stanley\",\n",
    "    }\n",
    "    bank_code = parts[0].lower()\n",
    "    quarter = parts[1].upper() if len(parts) > 1 else \"UNKNOWN\"\n",
    "    bank = bank_map.get(bank_code, bank_code.upper())\n",
    "    return bank, quarter\n",
    "def create_chunks_with_ollama(text: str, metadata: dict = None):\n",
    "    embedder = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "    chunker = SemanticChunker(embeddings=embedder, min_chunk_size=2000)\n",
    "\n",
    "    doc = Document(page_content=text, metadata=metadata or {})\n",
    "    return chunker.split_documents([doc])\n",
    "def search_chunks(chunks, parsed_query: ParsedRequest, top_k=5):\n",
    "    embedder = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "    vectorstore = FAISS.from_documents(chunks, embedder)\n",
    "\n",
    "    query_text = (\n",
    "        f\"Find information about {', '.join(parsed_query.metrics)} \"\n",
    "        f\"for banks like {', '.join(parsed_query.banks)} \"\n",
    "        f\"during quarters such as {', '.join(parsed_query.quarters)}\"\n",
    "    )\n",
    "\n",
    "    return vectorstore.similarity_search(query_text, k=top_k)\n",
    "def rerank_with_chatollama(chunks, parsed_query: ParsedRequest):\n",
    "    llm = ChatOllama(model=\"llama3.2:3b\")\n",
    "    context = \"\\n\\n\".join([chunk.page_content for chunk in chunks])\n",
    "\n",
    "    prompt = (\n",
    "        f\"You are a financial analyst assistant.\\n\\n\"\n",
    "        f\"Query:\\n{parsed_query.model_dump_json(indent=2)}\\n\\n\"\n",
    "        f\"Extracted text:\\n{context}\\n\\n\"\n",
    "        f\"Please summarize the relevant details in a table or paragraph based on the query intent.\"\n",
    "    )\n",
    "\n",
    "    response = llm.invoke([HumanMessage(content=prompt)])\n",
    "\n",
    "    return response.content\n",
    "all_chunks = []\n",
    "\n",
    "for pdf in os.listdir(full_path):\n",
    "    if not pdf.lower().endswith(\".pdf\"):\n",
    "        continue\n",
    "\n",
    "    pdf_path = os.path.join(full_path, pdf)\n",
    "    print(f\" Processing: {pdf}\")\n",
    "\n",
    "    bank, quarter = parse_filename_metadata(pdf)\n",
    "    clean_text = extract_text_excluding_tables(pdf_path)\n",
    "\n",
    "    # Wrap in custom tags for traceability\n",
    "    tagged_text = f\"<{bank} {quarter}>\\n{clean_text}\\n</{bank} {quarter}>\"\n",
    "\n",
    "    # Metadata\n",
    "    metadata = {\n",
    "        \"source\": pdf,\n",
    "        \"bank\": bank,\n",
    "        \"quarter\": quarter\n",
    "    }\n",
    "\n",
    "    # Chunk with metadata\n",
    "    chunks = create_chunks_with_ollama(tagged_text, metadata)\n",
    "    all_chunks.extend(chunks)\n",
    "\n",
    "# Print preview\n",
    "print(f\"\\nTotal Chunks Created: {len(all_chunks)}\")\n",
    "for i, chunk in enumerate(all_chunks[:3]):\n",
    "    print(f\"\\n--- Chunk {i+1} ---\")\n",
    "    print(\"Metadata:\", chunk.metadata)\n",
    "    print(\"Content preview:\", chunk.page_content[:300], \"...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5db33e6-e5aa-4837-9f2d-d65e3cb70d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# structured_query = '''{\n",
    "#     \"intent\": \"in-depth\",\n",
    "#     \"banks\": [\"JP Morgan Chase\", \"Bank of America\"],\n",
    "#     \"quarters\": [\"1Q2025\", \"4Q2024\", \"3Q2024\"],\n",
    "#     \"metrics\": [\"EarningsPerShare\", \"NetIncome\"]\n",
    "# }'''\n",
    "print(intent,input_params)\n",
    "structured_query = {**intent, **input_params}\n",
    "print(structured_query)\n",
    "structured_query_json = json.dumps(structured_query, indent=2)\n",
    "print(structured_query_json)\n",
    "parsed_query = ParsedRequest.model_validate(json.loads(structured_query_json))\n",
    "\n",
    "# Search top relevant chunks based on user's intent\n",
    "\n",
    "# Generate final answer with LLM (LLaMA 3.2)\n",
    "# final_answer = rerank_with_chatollama(matched_chunks, parsed_query)\n",
    "# print(final_answer)\n",
    "matched_chunks = search_chunks(all_chunks, parsed_query, top_k=5)\n",
    "\n",
    "# Print matched chunks directly\n",
    "final_ans=\"\"\n",
    "for i, chunk in enumerate(matched_chunks):\n",
    "    print(f\"\\n--- Matched Chunk {i+1} ---\")\n",
    "    # print(\"Metadata:\", chunk.metadata)\n",
    "    # print(\"Content:\\n\", chunk.page_content)\n",
    "    final_ans+=chunk.page_content\n",
    "print(final_ans)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d807c6f-699e-4b90-93b0-d353cfd28b9f",
   "metadata": {},
   "source": [
    "**EXCEL EXTRACTION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a432c7-04c0-40b9-b0c1-30a54e8cf785",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def convert_to_quarter(date_str):\n",
    "    \"\"\"Convert a date to '1Q2025' style format.\"\"\"\n",
    "    date = pd.to_datetime(date_str)\n",
    "    quarter = (date.month - 1) // 3 + 1\n",
    "    return f\"{quarter}Q{date.year}\"\n",
    "\n",
    "def get_financial_data(excel_path: str, input_data: dict) -> dict:\n",
    "    # Load Excel\n",
    "    df = pd.read_excel(excel_path)\n",
    "\n",
    "    # Clean columns and parse quarter\n",
    "    df.columns = df.columns.str.strip()\n",
    "    df['Quarter'] = df['Datetime'].apply(convert_to_quarter)\n",
    "\n",
    "    # Input filters\n",
    "    banks = input_data.get(\"banks\", [])\n",
    "    quarters = input_data.get(\"quarters\", [])\n",
    "    metrics = input_data.get(\"metrics\", [])\n",
    "\n",
    "    result = {}\n",
    "\n",
    "    for bank in banks:\n",
    "        bank_df = df[df['CompanyName'].str.strip() == bank.strip()]\n",
    "        if bank_df.empty:\n",
    "            continue\n",
    "\n",
    "        bank_result = {}\n",
    "        for quarter in quarters:\n",
    "            quarter_df = bank_df[bank_df['Quarter'] == quarter]\n",
    "            if quarter_df.empty:\n",
    "                continue\n",
    "\n",
    "            row = quarter_df.iloc[0]  # Take first match\n",
    "            quarter_metrics = {}\n",
    "\n",
    "            for metric in metrics:\n",
    "                if metric in row:\n",
    "                    quarter_metrics[metric] = row[metric]\n",
    "                else:\n",
    "                    quarter_metrics[metric] = None  # metric missing\n",
    "\n",
    "            bank_result[quarter] = quarter_metrics\n",
    "\n",
    "        result[bank] = bank_result\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e2baf8-0ecd-4768-9216-e7188a3f969d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_json = structured_query_json\n",
    "input1=(json.loads(structured_query_json))\n",
    "print(type(input1))\n",
    "print(type(input1.get('banks')))\n",
    "excel_path = sec_excel_path\n",
    "output = get_financial_data(excel_path, input1)\n",
    "\n",
    "# Pretty print\n",
    "table_output=json.dumps(output, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2092f57c-7e5b-46ab-a37e-4225c7c40abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_output=json.dumps(output, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2bb150-354a-4804-a273-7a90ec80643e",
   "metadata": {},
   "source": [
    "**Final Table and Text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77196bf5-e9fe-481e-9b3e-1bdaf07a15ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def generate_financial_html_response(llm_model_name: str, parsed_query: dict, extracted_text: str) -> str:\n",
    "    llm = ChatOllama(model=llm_model_name)\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are a professional financial analyst creating an internal report for Wells Fargo senior leadership.\n",
    "Your response must contain three clearly formatted parts in HTML TAgs with embedded CSS to make it visually appealing and boardroom-ready.\n",
    "\n",
    "### Instructions:\n",
    "1. **Part 1**: Present the input JSON request as a table and add HTML Table tags (no changes in values).\n",
    "2. **Part 2**: Use the extracted text to create a detailed narrative summary based on the below question asked. Structure this as a qualitative analysis that highlights trends, anomalies, risks, and growth areas.\n",
    "3. **Part 3**: Ensure the writing style is impressive to senior executives — use formal, insightful, and concise language.\n",
    "\n",
    "### Formatting Rules:\n",
    "- Use <table>, <thead>, <tbody>, <tr>, <th>, <td> for tables\n",
    "- Use <p>, <h2>, <h3> for textual sections\n",
    "- Use inline CSS to match Wells Fargo branding (deep red: #b31b1b, gold: #ffd700, and professional fonts)\n",
    "- Make layout visually appealing (padding, borders, alternating row colors, aligned text)\n",
    "- Output ONLY valid HTML tags (no Markdown or commentary)\n",
    "\n",
    "---\n",
    "\n",
    "JSON Request:\n",
    "```json\n",
    "{parsed_query}\n",
    "```\n",
    "\n",
    "Extracted Report Text:\n",
    "{extracted_text}\n",
    "\n",
    "User question :\n",
    "{question}\n",
    "\"\"\"\n",
    "\n",
    "    response = llm.invoke([HumanMessage(content=prompt.strip())])\n",
    "    return response.content\n",
    "\n",
    "# Example usage\n",
    "# html_output = generate_financial_html_response(\"qwen2.5:7b\", parsed_query, extracted_text)\n",
    "# display(HTML(html_output))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752e8625-4c83-4ad1-842f-27ad2dfa99c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example parsed_query dict\n",
    "parsed_query = input1\n",
    "\n",
    "# Example: Create a string of matched chunk content\n",
    "\n",
    "\n",
    "# Call function\n",
    "html_output = generate_detailed_html_report(llm_model_name, parsed_query, final_ans)\n",
    "\n",
    "# Optionally write to HTML file\n",
    "display(HTML(html_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1a5406-26a3-4289-8ba6-558a472a6b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "(html_output.split(\"</think>\")[-1].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c54b57a-e911-430b-af8a-7483199d8172",
   "metadata": {},
   "outputs": [],
   "source": [
    "html_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c041e32-8f0a-427d-8e92-541a3c2f21b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59fb2a13-ea5b-4dd7-9ae8-015c67bd9884",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error raised by inference API HTTP code: 404, {\"error\":\"model \\\"nomic-embed-text:v1.5\\\" not found, try pulling it first\"}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     12\u001b[39m embedding = OllamaEmbeddings(model=\u001b[33m\"\u001b[39m\u001b[33mnomic-embed-text:v1.5\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     13\u001b[39m splitter = SemanticChunker(embedding)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m split_docs = \u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# 2. Vector DB\u001b[39;00m\n\u001b[32m     17\u001b[39m db = FAISS.from_documents(split_docs, embedding)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langchain_experimental\\text_splitter.py:295\u001b[39m, in \u001b[36mSemanticChunker.split_documents\u001b[39m\u001b[34m(self, documents)\u001b[39m\n\u001b[32m    293\u001b[39m     texts.append(doc.page_content)\n\u001b[32m    294\u001b[39m     metadatas.append(doc.metadata)\n\u001b[32m--> \u001b[39m\u001b[32m295\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcreate_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langchain_experimental\\text_splitter.py:280\u001b[39m, in \u001b[36mSemanticChunker.create_documents\u001b[39m\u001b[34m(self, texts, metadatas)\u001b[39m\n\u001b[32m    278\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, text \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(texts):\n\u001b[32m    279\u001b[39m     start_index = \u001b[32m0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m280\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msplit_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    281\u001b[39m         metadata = copy.deepcopy(_metadatas[i])\n\u001b[32m    282\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._add_start_index:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langchain_experimental\\text_splitter.py:228\u001b[39m, in \u001b[36mSemanticChunker.split_text\u001b[39m\u001b[34m(self, text)\u001b[39m\n\u001b[32m    223\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    224\u001b[39m     \u001b[38;5;28mself\u001b[39m.breakpoint_threshold_type == \u001b[33m\"\u001b[39m\u001b[33mgradient\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    225\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(single_sentences_list) == \u001b[32m2\u001b[39m\n\u001b[32m    226\u001b[39m ):\n\u001b[32m    227\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m single_sentences_list\n\u001b[32m--> \u001b[39m\u001b[32m228\u001b[39m distances, sentences = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_calculate_sentence_distances\u001b[49m\u001b[43m(\u001b[49m\u001b[43msingle_sentences_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    229\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.number_of_chunks \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    230\u001b[39m     breakpoint_distance_threshold = \u001b[38;5;28mself\u001b[39m._threshold_from_clusters(distances)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langchain_experimental\\text_splitter.py:203\u001b[39m, in \u001b[36mSemanticChunker._calculate_sentence_distances\u001b[39m\u001b[34m(self, single_sentences_list)\u001b[39m\n\u001b[32m    199\u001b[39m _sentences = [\n\u001b[32m    200\u001b[39m     {\u001b[33m\"\u001b[39m\u001b[33msentence\u001b[39m\u001b[33m\"\u001b[39m: x, \u001b[33m\"\u001b[39m\u001b[33mindex\u001b[39m\u001b[33m\"\u001b[39m: i} \u001b[38;5;28;01mfor\u001b[39;00m i, x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(single_sentences_list)\n\u001b[32m    201\u001b[39m ]\n\u001b[32m    202\u001b[39m sentences = combine_sentences(_sentences, \u001b[38;5;28mself\u001b[39m.buffer_size)\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m embeddings = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m.\u001b[49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcombined_sentence\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msentences\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    205\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, sentence \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(sentences):\n\u001b[32m    207\u001b[39m     sentence[\u001b[33m\"\u001b[39m\u001b[33mcombined_sentence_embedding\u001b[39m\u001b[33m\"\u001b[39m] = embeddings[i]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langchain_community\\embeddings\\ollama.py:214\u001b[39m, in \u001b[36mOllamaEmbeddings.embed_documents\u001b[39m\u001b[34m(self, texts)\u001b[39m\n\u001b[32m    205\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Embed documents using an Ollama deployed embedding model.\u001b[39;00m\n\u001b[32m    206\u001b[39m \n\u001b[32m    207\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    211\u001b[39m \u001b[33;03m    List of embeddings, one for each text.\u001b[39;00m\n\u001b[32m    212\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    213\u001b[39m instruction_pairs = [\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.embed_instruction\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m texts]\n\u001b[32m--> \u001b[39m\u001b[32m214\u001b[39m embeddings = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_embed\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstruction_pairs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m embeddings\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langchain_community\\embeddings\\ollama.py:202\u001b[39m, in \u001b[36mOllamaEmbeddings._embed\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    200\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    201\u001b[39m     iter_ = \u001b[38;5;28minput\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m202\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_process_emb_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m iter_]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langchain_community\\embeddings\\ollama.py:176\u001b[39m, in \u001b[36mOllamaEmbeddings._process_emb_response\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    173\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError raised by inference endpoint: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m res.status_code != \u001b[32m200\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m176\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    177\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mError raised by inference API HTTP code: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m, \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    178\u001b[39m         % (res.status_code, res.text)\n\u001b[32m    179\u001b[39m     )\n\u001b[32m    180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    181\u001b[39m     t = res.json()\n",
      "\u001b[31mValueError\u001b[39m: Error raised by inference API HTTP code: 404, {\"error\":\"model \\\"nomic-embed-text:v1.5\\\" not found, try pulling it first\"}"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OllamaEmbeddings\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# 1. Load and split docs\n",
    "loader = TextLoader(\"citi.txt\", encoding='utf-8')\n",
    "docs = loader.load()\n",
    "embedding = OllamaEmbeddings(model=\"nomic-embed-text:v1.5\")\n",
    "splitter = SemanticChunker(embedding)\n",
    "split_docs = splitter.split_documents(docs)\n",
    "\n",
    "# 2. Vector DB\n",
    "db = FAISS.from_documents(split_docs, embedding)\n",
    "\n",
    "# 3. Base LLM\n",
    "llm = ChatOllama(model=\"llama3.2:3b\")\n",
    "\n",
    "# 4. Multi-query retriever\n",
    "multi_query_retriever = MultiQueryRetriever.from_llm(\n",
    "    retriever=db.as_retriever(), llm=llm\n",
    ")\n",
    "\n",
    "# 5. QA chain with multi-query retriever\n",
    "qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=multi_query_retriever)\n",
    "\n",
    "# 6. Ask a question\n",
    "response = qa_chain.run(\"What is the EPS of citi bank in 2025 Q1?\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c4f3b9-7d78-4e65-bf7d-6dad85906618",
   "metadata": {},
   "source": [
    "📄 Text File (citi.txt)\n",
    "   ↓\n",
    "🧩 Split into Chunks\n",
    "   ↓\n",
    "🔢 Embedded into Vectors\n",
    "   ↓\n",
    "🗃️ Stored in FAISS\n",
    "   ↓\n",
    "❓ You Ask a Question\n",
    "   ↓\n",
    "🔍 Relevant Chunks Retrieved\n",
    "   ↓\n",
    "🧠 Sent to LLM (LLaMA 3.2)\n",
    "   ↓\n",
    "💬 Final Answer Generated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7928e6c-004b-4aa9-a75a-67763283f4bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The diluted EPS (Earnings Per Share) for Citigroup Inc. in Q1 2025 was $1.96 per share.\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OllamaEmbeddings\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "class MultiPromptQA:\n",
    "    def __init__(self, file_path: str, embedding_model: str, llm_model: str):\n",
    "        self.file_path = file_path\n",
    "        self.embedding_model = embedding_model\n",
    "        self.llm_model = llm_model\n",
    "\n",
    "        self.docs = self.load_and_split()\n",
    "        self.db = self.create_vectorstore()\n",
    "        self.llm = ChatOllama(model=self.llm_model)\n",
    "        self.retriever = self.create_multi_query_retriever()\n",
    "        self.qa_chain = RetrievalQA.from_chain_type(llm=self.llm, retriever=self.retriever)\n",
    "\n",
    "    def load_and_split(self):\n",
    "        loader = TextLoader(self.file_path, encoding='utf-8')\n",
    "        docs = loader.load()\n",
    "\n",
    "        embedding = OllamaEmbeddings(model=self.embedding_model)\n",
    "        splitter = SemanticChunker(embedding)\n",
    "        split_docs = splitter.split_documents(docs)\n",
    "\n",
    "        return split_docs\n",
    "\n",
    "    def create_vectorstore(self):\n",
    "        embedding = OllamaEmbeddings(model=self.embedding_model)\n",
    "        return FAISS.from_documents(self.docs, embedding)\n",
    "\n",
    "    def create_multi_query_retriever(self):\n",
    "        return MultiQueryRetriever.from_llm(\n",
    "            retriever=self.db.as_retriever(),\n",
    "            llm=self.llm,\n",
    "            include_original=True\n",
    "        )\n",
    "\n",
    "    def ask(self, question: str) -> str:\n",
    "        return self.qa_chain.run(question)\n",
    "\n",
    "\n",
    "qa = MultiPromptQA(\n",
    "    file_path=\"C:/Users/Akshaya V/git/Earnings research/Earnings_agent/citi.txt\",\n",
    "    embedding_model=\"qwen2.5:0.5b\",\n",
    "    llm_model=\"qwen2.5:7b\"\n",
    ")\n",
    "\n",
    "response = qa.ask(\"What is the EPS of citi in 2025Q1?\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2306b368-5784-4afc-9cd0-681d8b4064a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OllamaEmbeddings\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "class MultiPromptQA:\n",
    "    def __init__(self, file_paths: list, embedding_model: str, llm_model: str):\n",
    "        self.file_paths = file_paths\n",
    "        self.embedding_model = embedding_model\n",
    "        self.llm_model = llm_model\n",
    "\n",
    "        self.docs = self.load_and_split_all()\n",
    "        self.db = self.create_vectorstore()\n",
    "        self.llm = ChatOllama(model=self.llm_model)\n",
    "        self.retriever = self.create_multi_query_retriever()\n",
    "        self.qa_chain = RetrievalQA.from_chain_type(llm=self.llm, retriever=self.retriever)\n",
    "\n",
    "    def load_and_split_all(self):\n",
    "        all_split_docs = []\n",
    "        embedding = OllamaEmbeddings(model=self.embedding_model)\n",
    "        splitter = SemanticChunker(embedding)\n",
    "\n",
    "        for path in self.file_paths:\n",
    "            loader = TextLoader(path, encoding='utf-8')\n",
    "            docs = loader.load()\n",
    "            split_docs = splitter.split_documents(docs)\n",
    "            all_split_docs.extend(split_docs)\n",
    "\n",
    "        return all_split_docs\n",
    "\n",
    "    def create_vectorstore(self):\n",
    "        embedding = OllamaEmbeddings(model=self.embedding_model)\n",
    "        return FAISS.from_documents(self.docs, embedding)\n",
    "\n",
    "    def create_multi_query_retriever(self):\n",
    "        return MultiQueryRetriever.from_llm(\n",
    "            retriever=self.db.as_retriever(),\n",
    "            llm=self.llm,\n",
    "            include_original=True\n",
    "        )\n",
    "\n",
    "    def ask(self, question: str) -> str:\n",
    "        return self.qa_chain.run(question)\n",
    "qa = MultiPromptQA(\n",
    "    file_paths=[\n",
    "        \"C:/Users/Akshaya V/git/Earnings research/Earnings_agent/citi.txt\",\n",
    "        \"C:/Users/Akshaya V/git/Earnings research/Earnings_agent/jpmc.txt\"\n",
    "    ],\n",
    "    embedding_model=\"qwen2.5:0.5b\",\n",
    "    llm_model=\"qwen2.5:7b\"\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156fc57d-56a1-46eb-ad27-8adfb6c530c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = qa.ask(\"Compare the EPS of Citi and JPMorgan in 2025Q1.\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc951dd-9afa-427a-9727-013a7568fa61",
   "metadata": {},
   "outputs": [],
   "source": [
    "$$ \n",
    "RAG + ReACT \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4846682-d136-4e96-b6cf-140b62221877",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mQuestion: Compare the EPS and net income of Citi in Q12025?\n",
      "Thought: I can use the earnings_qa_tool to answer this question.\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"earnings_qa_tool\",\n",
      "  \"action_input\": {\n",
      "    \"company\": \"Citi\",\n",
      "    \"quarter\": \"Q1\",\n",
      "    \"year\": \"2025\"\n",
      "  }\n",
      "}\n",
      "```\n",
      "\u001b[0m"
     ]
    },
    {
     "ename": "ToolException",
     "evalue": "Too many arguments to single-input tool earnings_qa_tool.\n                Consider using StructuredTool instead. Args: ['Citi', 'Q1', '2025']",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mToolException\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 107\u001b[39m\n\u001b[32m     97\u001b[39m agent = initialize_agent(\n\u001b[32m     98\u001b[39m     tools=tools,\n\u001b[32m     99\u001b[39m     llm=llm,\n\u001b[32m   (...)\u001b[39m\u001b[32m    103\u001b[39m     handle_parsing_errors=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    104\u001b[39m )\n\u001b[32m    106\u001b[39m \u001b[38;5;66;03m# ✅ Ask the agent something\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m107\u001b[39m response = \u001b[43magent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mCompare the EPS, net income of citi in Q12025?\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    108\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m🤖 Final Answer:\u001b[39m\u001b[33m\"\u001b[39m, response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:191\u001b[39m, in \u001b[36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    189\u001b[39m     warned = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    190\u001b[39m     emit_warning()\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langchain\\chains\\base.py:603\u001b[39m, in \u001b[36mChain.run\u001b[39m\u001b[34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[39m\n\u001b[32m    601\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) != \u001b[32m1\u001b[39m:\n\u001b[32m    602\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33m`run` supports only one positional argument.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m603\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m[\n\u001b[32m    604\u001b[39m         _output_key\n\u001b[32m    605\u001b[39m     ]\n\u001b[32m    607\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[32m    608\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(kwargs, callbacks=callbacks, tags=tags, metadata=metadata)[\n\u001b[32m    609\u001b[39m         _output_key\n\u001b[32m    610\u001b[39m     ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:191\u001b[39m, in \u001b[36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    189\u001b[39m     warned = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    190\u001b[39m     emit_warning()\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langchain\\chains\\base.py:386\u001b[39m, in \u001b[36mChain.__call__\u001b[39m\u001b[34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[39m\n\u001b[32m    354\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[32m    355\u001b[39m \n\u001b[32m    356\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    377\u001b[39m \u001b[33;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[32m    378\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    379\u001b[39m config = {\n\u001b[32m    380\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcallbacks\u001b[39m\u001b[33m\"\u001b[39m: callbacks,\n\u001b[32m    381\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtags\u001b[39m\u001b[33m\"\u001b[39m: tags,\n\u001b[32m    382\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: metadata,\n\u001b[32m    383\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mrun_name\u001b[39m\u001b[33m\"\u001b[39m: run_name,\n\u001b[32m    384\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m386\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRunnableConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    389\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    390\u001b[39m \u001b[43m    \u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[43m=\u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langchain\\chains\\base.py:167\u001b[39m, in \u001b[36mChain.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    166\u001b[39m     run_manager.on_chain_error(e)\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    168\u001b[39m run_manager.on_chain_end(outputs)\n\u001b[32m    170\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langchain\\chains\\base.py:157\u001b[39m, in \u001b[36mChain.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    155\u001b[39m     \u001b[38;5;28mself\u001b[39m._validate_inputs(inputs)\n\u001b[32m    156\u001b[39m     outputs = (\n\u001b[32m--> \u001b[39m\u001b[32m157\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    158\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[32m    159\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call(inputs)\n\u001b[32m    160\u001b[39m     )\n\u001b[32m    162\u001b[39m     final_outputs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] = \u001b[38;5;28mself\u001b[39m.prep_outputs(\n\u001b[32m    163\u001b[39m         inputs, outputs, return_only_outputs\n\u001b[32m    164\u001b[39m     )\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langchain\\agents\\agent.py:1620\u001b[39m, in \u001b[36mAgentExecutor._call\u001b[39m\u001b[34m(self, inputs, run_manager)\u001b[39m\n\u001b[32m   1618\u001b[39m \u001b[38;5;66;03m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[32m   1619\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m._should_continue(iterations, time_elapsed):\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m     next_step_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_take_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1621\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1622\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1623\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1624\u001b[39m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1625\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1626\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1627\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[32m   1628\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._return(\n\u001b[32m   1629\u001b[39m             next_step_output, intermediate_steps, run_manager=run_manager\n\u001b[32m   1630\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langchain\\agents\\agent.py:1328\u001b[39m, in \u001b[36mAgentExecutor._take_next_step\u001b[39m\u001b[34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[39m\n\u001b[32m   1317\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_take_next_step\u001b[39m(\n\u001b[32m   1318\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1319\u001b[39m     name_to_tool_map: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, BaseTool],\n\u001b[32m   (...)\u001b[39m\u001b[32m   1323\u001b[39m     run_manager: Optional[CallbackManagerForChainRun] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1324\u001b[39m ) -> Union[AgentFinish, \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mtuple\u001b[39m[AgentAction, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[32m   1325\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._consume_next_step(\n\u001b[32m   1326\u001b[39m         \u001b[43m[\u001b[49m\n\u001b[32m   1327\u001b[39m \u001b[43m            \u001b[49m\u001b[43ma\u001b[49m\n\u001b[32m-> \u001b[39m\u001b[32m1328\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_iter_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1329\u001b[39m \u001b[43m                \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1330\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1331\u001b[39m \u001b[43m                \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1332\u001b[39m \u001b[43m                \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1333\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1334\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1335\u001b[39m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m   1336\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langchain\\agents\\agent.py:1411\u001b[39m, in \u001b[36mAgentExecutor._iter_next_step\u001b[39m\u001b[34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[39m\n\u001b[32m   1409\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m agent_action\n\u001b[32m   1410\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m agent_action \u001b[38;5;129;01min\u001b[39;00m actions:\n\u001b[32m-> \u001b[39m\u001b[32m1411\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_perform_agent_action\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1412\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magent_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\n\u001b[32m   1413\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langchain\\agents\\agent.py:1433\u001b[39m, in \u001b[36mAgentExecutor._perform_agent_action\u001b[39m\u001b[34m(self, name_to_tool_map, color_mapping, agent_action, run_manager)\u001b[39m\n\u001b[32m   1431\u001b[39m         tool_run_kwargs[\u001b[33m\"\u001b[39m\u001b[33mllm_prefix\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1432\u001b[39m     \u001b[38;5;66;03m# We then call the tool on the tool input to get an observation\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1433\u001b[39m     observation = \u001b[43mtool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1434\u001b[39m \u001b[43m        \u001b[49m\u001b[43magent_action\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtool_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1435\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1436\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1437\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1438\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtool_run_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1439\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1440\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1441\u001b[39m     tool_run_kwargs = \u001b[38;5;28mself\u001b[39m._action_agent.tool_run_logging_kwargs()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langchain_core\\tools\\base.py:771\u001b[39m, in \u001b[36mBaseTool.run\u001b[39m\u001b[34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[39m\n\u001b[32m    769\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m error_to_raise:\n\u001b[32m    770\u001b[39m     run_manager.on_tool_error(error_to_raise)\n\u001b[32m--> \u001b[39m\u001b[32m771\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m error_to_raise\n\u001b[32m    772\u001b[39m output = _format_output(content, artifact, tool_call_id, \u001b[38;5;28mself\u001b[39m.name, status)\n\u001b[32m    773\u001b[39m run_manager.on_tool_end(output, color=color, name=\u001b[38;5;28mself\u001b[39m.name, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langchain_core\\tools\\base.py:733\u001b[39m, in \u001b[36mBaseTool.run\u001b[39m\u001b[34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[39m\n\u001b[32m    731\u001b[39m child_config = patch_config(config, callbacks=run_manager.get_child())\n\u001b[32m    732\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m     tool_args, tool_kwargs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_to_args_and_kwargs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtool_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_call_id\u001b[49m\n\u001b[32m    735\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    736\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m signature(\u001b[38;5;28mself\u001b[39m._run).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    737\u001b[39m         tool_kwargs = tool_kwargs | {\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m: run_manager}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langchain_core\\tools\\simple.py:89\u001b[39m, in \u001b[36mTool._to_args_and_kwargs\u001b[39m\u001b[34m(self, tool_input, tool_call_id)\u001b[39m\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(all_args) != \u001b[32m1\u001b[39m:\n\u001b[32m     84\u001b[39m     msg = (\n\u001b[32m     85\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\u001b[33mToo many arguments to single-input tool \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\n\u001b[32m     86\u001b[39m \u001b[33m        Consider using StructuredTool instead.\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m     87\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m Args: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mall_args\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     88\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m89\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ToolException(msg)\n\u001b[32m     90\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(all_args), {}\n",
      "\u001b[31mToolException\u001b[39m: Too many arguments to single-input tool earnings_qa_tool.\n                Consider using StructuredTool instead. Args: ['Citi', 'Q1', '2025']"
     ]
    }
   ],
   "source": [
    "# Ensure required packages are installed:\n",
    "# pip install langchain pypdf faiss-cpu\n",
    "\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OllamaEmbeddings\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain.document_loaders import PyPDFLoader, TextLoader\n",
    "from langchain.chat_models import ChatOllama\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.agents.agent_types import AgentType\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.tools import tool\n",
    "\n",
    "# 🔧 MultiPromptQA class definition with PDF support\n",
    "class MultiPromptQA:\n",
    "    def __init__(self, file_paths: list, embedding_model: str, llm_model: str):\n",
    "        self.file_paths = file_paths\n",
    "        self.embedding_model = embedding_model\n",
    "        self.llm_model = llm_model\n",
    "\n",
    "        self.docs = self.load_and_split_all()\n",
    "        self.db = self.create_vectorstore()\n",
    "        self.llm = ChatOllama(model=self.llm_model)\n",
    "        self.retriever = self.create_multi_query_retriever()\n",
    "        self.qa_chain = RetrievalQA.from_chain_type(llm=self.llm, retriever=self.retriever)\n",
    "\n",
    "    def load_and_split_all(self):\n",
    "        all_split_docs = []\n",
    "        embedding = OllamaEmbeddings(model=self.embedding_model)\n",
    "        splitter = SemanticChunker(embedding)\n",
    "\n",
    "        for path in self.file_paths:\n",
    "            loader = PyPDFLoader(path) if path.endswith(\".pdf\") else TextLoader(path, encoding='utf-8')\n",
    "            docs = loader.load()\n",
    "            split_docs = splitter.split_documents(docs)\n",
    "            all_split_docs.extend(split_docs)\n",
    "\n",
    "        return all_split_docs\n",
    "\n",
    "    def create_vectorstore(self):\n",
    "        embedding = OllamaEmbeddings(model=self.embedding_model)\n",
    "        return FAISS.from_documents(self.docs, embedding)\n",
    "\n",
    "    def create_multi_query_retriever(self):\n",
    "        return MultiQueryRetriever.from_llm(\n",
    "            retriever=self.db.as_retriever(),\n",
    "            llm=self.llm,\n",
    "            include_original=True\n",
    "        )\n",
    "\n",
    "    def ask(self, question: str) -> str:\n",
    "        return self.qa_chain.run(question)\n",
    "\n",
    "\n",
    "# ✅ Tool 1: Read a text or PDF file\n",
    "@tool\n",
    "def read_file(bank_file_name: str) -> str:\n",
    "    \"\"\"Reads the contents of a local text or PDF file. Example: 'citi.pdf' or 'jpmc.txt'\"\"\"\n",
    "    try:\n",
    "        file_path = f\"C:/Users/Akshaya V/git/CG/{bank_file_name}\"\n",
    "        if bank_file_name.endswith(\".pdf\"):\n",
    "            loader = PyPDFLoader(file_path)\n",
    "        else:\n",
    "            loader = TextLoader(file_path, encoding='utf-8')\n",
    "        pages = loader.load()\n",
    "        return \"\\n\\n\".join([p.page_content for p in pages])\n",
    "    except Exception as e:\n",
    "        return f\"Error reading file: {str(e)}\"\n",
    "\n",
    "\n",
    "# ✅ Tool 2: Wrap MultiPromptQA as a Tool\n",
    "rag_qa = MultiPromptQA(\n",
    "    file_paths=[\n",
    "        \"C:/Users/Akshaya V/git/Earnings research/Earnings_agent/citi.pdf\",\n",
    "        \"C:/Users/Akshaya V/git/Earnings research/Earnings_agent/jpmc.pdf\"\n",
    "    ],\n",
    "    embedding_model=\"qwen2.5:0.5b\",\n",
    "    llm_model=\"qwen2.5:7b\"\n",
    ")\n",
    "\n",
    "rag_tool = Tool(\n",
    "    name=\"earnings_qa_tool\",\n",
    "    func=rag_qa.ask,\n",
    "    description=\"Use this tool to answer questions related to quarterly earnings from Citi and JPMorgan PDF reports.\"\n",
    ")\n",
    "\n",
    "# ✅ Final tool list\n",
    "tools = [read_file, rag_tool]\n",
    "\n",
    "# ✅ Load LLM & memory\n",
    "llm = ChatOllama(model=\"llama3.2:3b\")\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "# ✅ Initialize the ReAct agent\n",
    "agent = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    "    memory=memory,\n",
    "    handle_parsing_errors=True\n",
    ")\n",
    "\n",
    "# ✅ Ask the agent something\n",
    "response = agent.run(\"Compare the EPS, net income of citi in Q12025?\")\n",
    "print(\"\\n🤖 Final Answer:\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa0742db-2e01-408b-b4ec-67dd1c330427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Fetching JPMorgan Chase & Co. 10-K for 2024...\n",
      "❗ Error: Couldn't find a tree builder with the features you requested: lxml-xml. Do you need to install a parser library?\n",
      "\n",
      "🔍 Fetching JPMorgan Chase & Co. 10-K for 2023...\n",
      "❗ Error: Couldn't find a tree builder with the features you requested: lxml-xml. Do you need to install a parser library?\n",
      "\n",
      "🔍 Fetching JPMorgan Chase & Co. 10-K for 2022...\n",
      "❗ Error: Couldn't find a tree builder with the features you requested: lxml-xml. Do you need to install a parser library?\n",
      "\n",
      "🔍 Fetching JPMorgan Chase & Co. 10-K for 2021...\n",
      "❗ Error: Couldn't find a tree builder with the features you requested: lxml-xml. Do you need to install a parser library?\n",
      "\n",
      "🔍 Fetching JPMorgan Chase & Co. 10-K for 2020...\n",
      "❗ Error: Couldn't find a tree builder with the features you requested: lxml-xml. Do you need to install a parser library?\n",
      "\n",
      "🔍 Fetching Bank of America Corporation 10-K for 2024...\n",
      "❗ Error: Couldn't find a tree builder with the features you requested: lxml-xml. Do you need to install a parser library?\n",
      "\n",
      "🔍 Fetching Bank of America Corporation 10-K for 2023...\n",
      "❗ Error: Couldn't find a tree builder with the features you requested: lxml-xml. Do you need to install a parser library?\n",
      "\n",
      "🔍 Fetching Bank of America Corporation 10-K for 2022...\n",
      "❗ Error: Couldn't find a tree builder with the features you requested: lxml-xml. Do you need to install a parser library?\n",
      "\n",
      "🔍 Fetching Bank of America Corporation 10-K for 2021...\n",
      "❗ Error: Couldn't find a tree builder with the features you requested: lxml-xml. Do you need to install a parser library?\n",
      "\n",
      "🔍 Fetching Bank of America Corporation 10-K for 2020...\n",
      "❗ Error: Couldn't find a tree builder with the features you requested: lxml-xml. Do you need to install a parser library?\n",
      "\n",
      "🔍 Fetching Citigroup Inc. 10-K for 2024...\n",
      "❗ Error: Couldn't find a tree builder with the features you requested: lxml-xml. Do you need to install a parser library?\n",
      "\n",
      "🔍 Fetching Citigroup Inc. 10-K for 2023...\n",
      "❗ Error: Couldn't find a tree builder with the features you requested: lxml-xml. Do you need to install a parser library?\n",
      "\n",
      "🔍 Fetching Citigroup Inc. 10-K for 2022...\n",
      "❗ Error: Couldn't find a tree builder with the features you requested: lxml-xml. Do you need to install a parser library?\n",
      "\n",
      "🔍 Fetching Citigroup Inc. 10-K for 2021...\n",
      "❗ Error: Couldn't find a tree builder with the features you requested: lxml-xml. Do you need to install a parser library?\n",
      "\n",
      "🔍 Fetching Citigroup Inc. 10-K for 2020...\n",
      "❗ Error: Couldn't find a tree builder with the features you requested: lxml-xml. Do you need to install a parser library?\n",
      "\n",
      "🔍 Fetching Wells Fargo & Company 10-K for 2024...\n",
      "❗ Error: Couldn't find a tree builder with the features you requested: lxml-xml. Do you need to install a parser library?\n",
      "\n",
      "🔍 Fetching Wells Fargo & Company 10-K for 2023...\n",
      "❗ Error: Couldn't find a tree builder with the features you requested: lxml-xml. Do you need to install a parser library?\n",
      "\n",
      "🔍 Fetching Wells Fargo & Company 10-K for 2022...\n",
      "❗ Error: Couldn't find a tree builder with the features you requested: lxml-xml. Do you need to install a parser library?\n",
      "\n",
      "🔍 Fetching Wells Fargo & Company 10-K for 2021...\n",
      "❗ Error: Couldn't find a tree builder with the features you requested: lxml-xml. Do you need to install a parser library?\n",
      "\n",
      "🔍 Fetching Wells Fargo & Company 10-K for 2020...\n",
      "❗ Error: Couldn't find a tree builder with the features you requested: lxml-xml. Do you need to install a parser library?\n",
      "\n",
      "✅ Download attempt complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# List of top US banks (CIKs are accurate)\n",
    "top_20_banks = [\n",
    "    (\"JPMorgan Chase & Co.\", \"0000019617\"),\n",
    "    (\"Bank of America Corporation\", \"0000070858\"),\n",
    "    (\"Citigroup Inc.\", \"0000831001\"),\n",
    "    (\"Wells Fargo & Company\", \"0000072971\")\n",
    "    # Add more as needed\n",
    "]\n",
    "\n",
    "search_url = \"https://www.sec.gov/cgi-bin/browse-edgar\"\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (compatible; SECFetcher/1.0)\"}\n",
    "\n",
    "\n",
    "def download_10k_filings(cik, company_name, years=5):\n",
    "    current_year = datetime.now().year\n",
    "    target_dir = f\"./sec_filings/{company_name.replace(' ', '_')}\"\n",
    "    os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "    for year in range(current_year - 1, current_year - years - 1, -1):\n",
    "        print(f\"\\n🔍 Fetching {company_name} 10-K for {year}...\")\n",
    "        params = {\n",
    "            \"action\": \"getcompany\",\n",
    "            \"CIK\": cik,\n",
    "            \"type\": \"10-K\",\n",
    "            \"dateb\": f\"{year}1231\",\n",
    "            \"owner\": \"exclude\",\n",
    "            \"count\": \"100\",\n",
    "            \"output\": \"atom\"\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            resp = requests.get(search_url, params=params, headers=headers)\n",
    "            if resp.status_code != 200:\n",
    "                print(f\"❌ Failed to fetch data for {year}\")\n",
    "                continue\n",
    "\n",
    "            soup = BeautifulSoup(resp.content, \"lxml-xml\")  # <-- FIX: use lxml-xml for XML parsing\n",
    "            entries = soup.find_all(\"entry\")\n",
    "\n",
    "            if not entries:\n",
    "                print(f\"⚠️ No entries found for {year}\")\n",
    "                continue\n",
    "\n",
    "            for entry in entries:\n",
    "                filing_date = entry.find(\"filing-date\").text\n",
    "                doc_url = entry.find(\"filing-href\").text.replace(\"-index.htm\", \".txt\")\n",
    "\n",
    "                print(f\"⬇️  Downloading 10-K from {filing_date}\")\n",
    "                filing_resp = requests.get(doc_url, headers=headers)\n",
    "                if filing_resp.status_code == 200:\n",
    "                    file_path = os.path.join(target_dir, f\"{company_name.replace(' ', '_')}_{filing_date}.txt\")\n",
    "                    with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                        f.write(filing_resp.text)\n",
    "                else:\n",
    "                    print(\"⚠️  Could not download 10-K.\")\n",
    "                break  # Only download the most recent 10-K per year\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❗ Error: {e}\")\n",
    "\n",
    "\n",
    "# Trigger downloads for each bank\n",
    "for name, cik in top_20_banks:\n",
    "    download_10k_filings(cik, name)\n",
    "\n",
    "print(\"\\n✅ Download attempt complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5cabb2-5a49-4e46-a25e-0df2b75608b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ Fix: Replace Tool with StructuredTool for multi-input handling\n",
    "from langchain.tools import StructuredTool\n",
    "from typing import Optional\n",
    "\n",
    "# 🧠 Fix MultiPromptQA ask method to accept kwargs\n",
    "class MultiPromptQA:\n",
    "    def __init__(self, file_paths: list, embedding_model: str, llm_model: str):\n",
    "        self.file_paths = file_paths\n",
    "        self.embedding_model = embedding_model\n",
    "        self.llm_model = llm_model\n",
    "\n",
    "        self.docs = self.load_and_split_all()\n",
    "        self.db = self.create_vectorstore()\n",
    "        self.llm = ChatOllama(model=self.llm_model)\n",
    "        self.retriever = self.create_multi_query_retriever()\n",
    "        self.qa_chain = RetrievalQA.from_chain_type(llm=self.llm, retriever=self.retriever)\n",
    "\n",
    "    def load_and_split_all(self):\n",
    "        all_split_docs = []\n",
    "        embedding = OllamaEmbeddings(model=self.embedding_model)\n",
    "        splitter = SemanticChunker(embedding)\n",
    "\n",
    "        for path in self.file_paths:\n",
    "            loader = PyPDFLoader(path) if path.endswith(\".pdf\") else TextLoader(path, encoding='utf-8')\n",
    "            docs = loader.load()\n",
    "            split_docs = splitter.split_documents(docs)\n",
    "            all_split_docs.extend(split_docs)\n",
    "\n",
    "        return all_split_docs\n",
    "\n",
    "    def create_vectorstore(self):\n",
    "        embedding = OllamaEmbeddings(model=self.embedding_model)\n",
    "        return FAISS.from_documents(self.docs, embedding)\n",
    "\n",
    "    def create_multi_query_retriever(self):\n",
    "        return MultiQueryRetriever.from_llm(\n",
    "            retriever=self.db.as_retriever(),\n",
    "            llm=self.llm,\n",
    "            include_original=True\n",
    "        )\n",
    "\n",
    "    def ask(self, question: str) -> str:\n",
    "        return self.qa_chain.run(question)\n",
    "\n",
    "# ✅ Use StructuredTool to pass multiple inputs properly\n",
    "rag_tool = StructuredTool.from_function(\n",
    "    name=\"earnings_qa_tool\",\n",
    "    func=rag_qa.ask,\n",
    "    description=\"Answer questions related to earnings from Citi and JPMorgan PDF reports. Accepts a question as input.\",\n",
    "    args_schema=None  # Only one string input needed: question\n",
    ")\n",
    "\n",
    "# 🔧 Re-initialize tools and agent with StructuredTool\n",
    "tools = [read_file, rag_tool]\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    "    memory=memory,\n",
    "    handle_parsing_errors=True\n",
    ")\n",
    "\n",
    "# ✅ Try again\n",
    "response = agent.run(\"Compare the EPS of Citi for Q12025\")\n",
    "print(\"\\n🤖 Final Answer:\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a926daf-5527-42d3-aec3-fb6fd3e2fcc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Akshaya V\\AppData\\Local\\Temp\\ipykernel_40200\\1014725998.py:55: LangChainDeprecationWarning: Please see migration guide here for recommended implementation: https://python.langchain.com/docs/versions/migrating_chains/multi_prompt_chain/\n",
      "  mcp_chain = MultiPromptChain(\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'LLMChain' object has no attribute 'get'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 55\u001b[39m\n\u001b[32m     52\u001b[39m router_chain = LLMChain(prompt=router_prompt, llm=llm)\n\u001b[32m     54\u001b[39m \u001b[38;5;66;03m# ✅ MCP chain\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m mcp_chain = \u001b[43mMultiPromptChain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrouter_chain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrouter_chain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     57\u001b[39m \n\u001b[32m     58\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdestination_chains\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mciti\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mRetrievalQA\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_chain_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m=\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretriever\u001b[49m\u001b[43m=\u001b[49m\u001b[43mciti_rag\u001b[49m\u001b[43m.\u001b[49m\u001b[43mretriever\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mjpmc\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mRetrievalQA\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_chain_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m=\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretriever\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjpmc_rag\u001b[49m\u001b[43m.\u001b[49m\u001b[43mretriever\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdefault_chain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mRetrievalQA\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_chain_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m=\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretriever\u001b[49m\u001b[43m=\u001b[49m\u001b[43mciti_rag\u001b[49m\u001b[43m.\u001b[49m\u001b[43mretriever\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     63\u001b[39m \n\u001b[32m     64\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m     65\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[38;5;66;03m# ✅ Plot tool with dynamic input\u001b[39;00m\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mplot_dynamic_chart\u001b[39m(data: \u001b[38;5;28mdict\u001b[39m, plot_type: \u001b[38;5;28mstr\u001b[39m = \u001b[33m\"\u001b[39m\u001b[33mbar\u001b[39m\u001b[33m\"\u001b[39m) -> \u001b[38;5;28mstr\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:224\u001b[39m, in \u001b[36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    222\u001b[39m     warned = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    223\u001b[39m     emit_warning()\n\u001b[32m--> \u001b[39m\u001b[32m224\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langchain_core\\load\\serializable.py:130\u001b[39m, in \u001b[36mSerializable.__init__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args: Any, **kwargs: Any) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    129\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: D419\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[31m[... skipping hidden 1 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langchain\\chains\\base.py:233\u001b[39m, in \u001b[36mChain.raise_callback_manager_deprecation\u001b[39m\u001b[34m(cls, values)\u001b[39m\n\u001b[32m    229\u001b[39m \u001b[38;5;129m@model_validator\u001b[39m(mode=\u001b[33m\"\u001b[39m\u001b[33mbefore\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    230\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m    231\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mraise_callback_manager_deprecation\u001b[39m(\u001b[38;5;28mcls\u001b[39m, values: \u001b[38;5;28mdict\u001b[39m) -> Any:\n\u001b[32m    232\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Raise deprecation warning if callback_manager is used.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m233\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mvalues\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m(\u001b[33m\"\u001b[39m\u001b[33mcallback_manager\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    234\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m values.get(\u001b[33m\"\u001b[39m\u001b[33mcallbacks\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    235\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    236\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mCannot specify both callback_manager and callbacks. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    237\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mcallback_manager is deprecated, callbacks is the preferred \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    238\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mparameter to pass in.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    239\u001b[39m             )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pydantic\\main.py:991\u001b[39m, in \u001b[36mBaseModel.__getattr__\u001b[39m\u001b[34m(self, item)\u001b[39m\n\u001b[32m    988\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__getattribute__\u001b[39m(item)  \u001b[38;5;66;03m# Raises AttributeError if appropriate\u001b[39;00m\n\u001b[32m    989\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    990\u001b[39m     \u001b[38;5;66;03m# this is the current error\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m991\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m object has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'LLMChain' object has no attribute 'get'"
     ]
    }
   ],
   "source": [
    "# ✅ MCP agent with RAG + MultiQueryRetriever + Dynamic Plotting\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OllamaEmbeddings\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chains.router import MultiPromptChain, RouterChain\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatOllama\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "from langchain.agents import Tool, initialize_agent, AgentType\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "# ✅ Load models\n",
    "llm = ChatOllama(model=\"llama3.2:3b\")\n",
    "embedding = OllamaEmbeddings(model=\"qwen2.5:0.5b\")\n",
    "\n",
    "# ✅ Build a MultiQueryRetriever-backed RAG chain\n",
    "def build_multi_rag_chain(file_path):\n",
    "    docs = PyPDFLoader(file_path).load()\n",
    "    chunks = SemanticChunker(embedding).split_documents(docs)\n",
    "    db = FAISS.from_documents(chunks, embedding)\n",
    "    retriever = MultiQueryRetriever.from_llm(\n",
    "        retriever=db.as_retriever(),\n",
    "        llm=llm,\n",
    "        include_original=True\n",
    "    )\n",
    "    return RetrievalQA.from_chain_type(llm=llm, retriever=retriever)\n",
    "\n",
    "# ✅ Define expert chains with bank-specific prompts\n",
    "citi_rag = build_multi_rag_chain(\"C:/Users/Akshaya V/git/Earnings research/Earnings_agent/citi.pdf\")\n",
    "jpmc_rag = build_multi_rag_chain(\"C:/Users/Akshaya V/git/Earnings research/Earnings_agent/jpmc.pdf\")\n",
    "\n",
    "citi_prompt = PromptTemplate.from_template(\n",
    "    \"You are an expert in Citi earnings reports. Answer this question using Citi data only:\\n{input}\"\n",
    ")\n",
    "jpmc_prompt = PromptTemplate.from_template(\n",
    "    \"You are an expert in JPMorgan earnings reports. Answer this question using JPMorgan data only:\\n{input}\"\n",
    ")\n",
    "\n",
    "citi_chain = LLMChain(prompt=citi_prompt, llm=llm)\n",
    "jpmc_chain = LLMChain(prompt=jpmc_prompt, llm=llm)\n",
    "\n",
    "# ✅ Router to pick the right chain based on query\n",
    "router_prompt = PromptTemplate.from_template(\n",
    "    \"Route this question to either 'citi' or 'jpmc' based on bank mentioned:\\n{input}\\nRoute:\"\n",
    ")\n",
    "router_chain = LLMChain(prompt=router_prompt, llm=llm)\n",
    "\n",
    "# ✅ MCP chain\n",
    "mcp_chain = MultiPromptChain(\n",
    "    router_chain=router_chain,\n",
    "\n",
    "    destination_chains={\n",
    "        \"citi\": RetrievalQA.from_chain_type(llm=llm, retriever=citi_rag.retriever),\n",
    "        \"jpmc\": RetrievalQA.from_chain_type(llm=llm, retriever=jpmc_rag.retriever),\n",
    "    },\n",
    "    default_chain=RetrievalQA.from_chain_type(llm=llm, retriever=citi_rag.retriever),\n",
    "\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# ✅ Plot tool with dynamic input\n",
    "\n",
    "def plot_dynamic_chart(data: dict, plot_type: str = \"bar\") -> str:\n",
    "    try:\n",
    "        banks = list(data.keys())\n",
    "        metrics = list(data[banks[0]].keys())\n",
    "        num_metrics = len(metrics)\n",
    "        x = range(len(banks))\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        width = 0.8 / num_metrics\n",
    "\n",
    "        for i, metric in enumerate(metrics):\n",
    "            values = [data[bank][metric] for bank in banks]\n",
    "            pos = [p + i * width for p in x]\n",
    "\n",
    "            if plot_type == \"bar\":\n",
    "                ax.bar(pos, values, width, label=metric)\n",
    "            elif plot_type == \"line\":\n",
    "                ax.plot([p + width * i for p in x], values, label=metric, marker='o')\n",
    "            elif plot_type == \"scatter\":\n",
    "                ax.scatter([p + width * i for p in x], values, label=metric)\n",
    "            else:\n",
    "                return f\"Unsupported plot type: {plot_type}\"\n",
    "\n",
    "        ax.set_title(\"Bank Earnings Comparison\")\n",
    "        ax.set_xticks([p + width * (num_metrics - 1) / 2 for p in x])\n",
    "        ax.set_xticklabels(banks)\n",
    "        ax.set_ylabel(\"Values\")\n",
    "        ax.legend()\n",
    "        plt.tight_layout()\n",
    "\n",
    "        filename = f\"earnings_plot_{plot_type}.png\"\n",
    "        plt.savefig(filename)\n",
    "        return f\"Chart saved as '{filename}'\"\n",
    "    except Exception as e:\n",
    "        return f\"Plotting error: {str(e)}\"\n",
    "\n",
    "# ✅ Tool wrapper for chart generator\n",
    "def user_plot_tool(input: str) -> str:\n",
    "    try:\n",
    "        parsed = json.loads(input)\n",
    "        return plot_dynamic_chart(parsed[\"data\"], parsed.get(\"plot_type\", \"bar\"))\n",
    "    except Exception as e:\n",
    "        return f\"Invalid input for plotting: {str(e)}\"\n",
    "\n",
    "plot_tool = Tool(\n",
    "    name=\"Earnings Chart Generator\",\n",
    "    func=user_plot_tool,\n",
    "    description=\"Generate charts (bar, line, scatter) comparing earnings metrics across banks. Accepts JSON input with plot_type and data.\"\n",
    ")\n",
    "\n",
    "# ✅ Load tools into a ReAct agent (MCP + plot)\n",
    "tools = [\n",
    "    Tool(name=\"MCP Earnings RAG\", func=mcp_chain.run, description=\"Ask any question about Citi or JPMorgan earnings.\"),\n",
    "    plot_tool\n",
    "]\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    "    memory=memory,\n",
    "    handle_parsing_errors=True\n",
    ")\n",
    "\n",
    "# ✅ Example usage\n",
    "response = agent.run(\"What was the net income of JPMorgan in Q1 2025?\")\n",
    "# response = agent.run('{\"plot_type\": \"bar\", \"data\": {\"Citi\": {\"EPS\": 1.2}, \"JPMorgan\": {\"EPS\": 1.6}}}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24dbf9b-49a9-4124-bfb5-3bba8b0be28e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_community.document_loaders import PyPDFLoader, UnstructuredExcelLoader\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "class RAGWithOllamaEmbed:\n",
    "    def __init__(self, data_dir=\"./data\", ollama_llm_model=\"qwen2:7b\", ollama_embed_model=\"nomic-embed-text\"):\n",
    "        self.data_dir = data_dir\n",
    "        self.ollama_llm_model = ollama_llm_model\n",
    "        self.ollama_embed_model = ollama_embed_model\n",
    "        self.embeddings = OllamaEmbeddings(model=self.ollama_embed_model)\n",
    "        self.documents = []\n",
    "        self.vectorstore = None\n",
    "        self.qa_chain = None\n",
    "\n",
    "    def load_documents(self):\n",
    "        for file in os.listdir(self.data_dir):\n",
    "            path = os.path.join(self.data_dir, file)\n",
    "            if file.endswith(\".pdf\"):\n",
    "                loader = PyPDFLoader(path)\n",
    "                self.documents.extend(loader.load())\n",
    "            elif file.endswith(\".xlsx\") or file.endswith(\".xls\"):\n",
    "                loader = UnstructuredExcelLoader(path)\n",
    "                self.documents.extend(loader.load())\n",
    "\n",
    "    def build_vectorstore(self):\n",
    "        chunker = SemanticChunker(\n",
    "            self.embeddings,\n",
    "            breakpoint_threshold_type=\"percentile\",\n",
    "            breakpoint_threshold_amount=90\n",
    "        )\n",
    "        chunks = chunker.split_documents(self.documents)\n",
    "        self.vectorstore = FAISS.from_documents(chunks, self.embeddings)\n",
    "\n",
    "    def setup_qa_chain(self):\n",
    "        retriever = self.vectorstore.as_retriever()\n",
    "        llm = ChatOllama(model=self.ollama_llm_model)\n",
    "        self.qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever, return_source_documents=False)\n",
    "\n",
    "    def answer_as_html(self, question: str) -> str:\n",
    "        if not self.qa_chain:\n",
    "            raise Exception(\"Call setup_qa_chain() before asking questions.\")\n",
    "        answer = self.qa_chain.run(question)\n",
    "\n",
    "        # Convert to HTML\n",
    "        soup = BeautifulSoup(\"\", \"html.parser\")\n",
    "        div = soup.new_tag(\"div\")\n",
    "        p = soup.new_tag(\"p\")\n",
    "        p.string = answer\n",
    "        div.append(p)\n",
    "        soup.append(div)\n",
    "        return str(soup)\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    rag = RAGWithOllamaEmbed(\n",
    "        data_dir=\"./data\",\n",
    "        ollama_llm_model=\"qwen2:7b\",\n",
    "        ollama_embed_model=\"nomic-embed-text\"  # Make sure this is pulled with Ollama\n",
    "    )\n",
    "    rag.load_documents()\n",
    "    rag.build_vectorstore()\n",
    "    rag.setup_qa_chain()\n",
    "\n",
    "    question = \"List the key financial observations from the reports.\"\n",
    "    html = rag.answer_as_html(question)\n",
    "\n",
    "    with open(\"response_ollama_embed.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(html)\n",
    "\n",
    "    print(\"✅ Response saved to response_ollama_embed.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffede4ac-81dc-401a-9695-a04a5b698261",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d531fb2-1f3d-45c9-841b-2ef21eacb4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Type\n",
    "from pydantic import BaseModel\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "import json\n",
    "\n",
    "# ---------------------------\n",
    "# 1. Define the Pydantic Schema\n",
    "# ---------------------------\n",
    "class ParsedRequest(BaseModel):\n",
    "    intent: str                 # \"table\", \"qualitative\", or \"in-depth\"\n",
    "    banks: List[str]            # Must match allowed_banks\n",
    "    quarters: List[str]         # e.g., \"1Q2025\", \"4Q2024\"\n",
    "    metrics: List[str]          # Must match allowed_metrics\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# 2. Function to Use ChatOllama with Pydantic Schema\n",
    "# ---------------------------\n",
    "def parse_with_chatollama(\n",
    "    llm_model_name: str,\n",
    "    user_input: str,\n",
    "    schema: Type[BaseModel],\n",
    "    allowed_banks: List[str],\n",
    "    allowed_metrics: List[str]\n",
    ") -> BaseModel:\n",
    "    system_prompt = f\"\"\"\n",
    "You are a financial assistant. Your task is to extract structured information from user input and return it in the following JSON format:\n",
    "\n",
    "{{\n",
    "  \"intent\": \"table\" | \"qualitative\" | \"in-depth\",\n",
    "  \"banks\": [valid bank names],\n",
    "  \"quarters\": [\"1Q2025\", \"4Q2024\", \"3Q2024\"],\n",
    "  \"metrics\": [valid metric keys]\n",
    "}}\n",
    "\n",
    "Rules:\n",
    "- Choose \"intent\" based on context: \"table\" (structured data), \"qualitative\" (light summary), \"in-depth\" (detailed analysis).\n",
    "- Map any abbreviation or alias to official bank names from this list: {json.dumps(allowed_banks)}\n",
    "- Extract all mentioned quarters in \"1Q2025\" format. Include the previous 2 quarters for each.\n",
    "- Extract only metrics listed here: {json.dumps(allowed_metrics)}.\n",
    "- Output only the JSON structure as shown above, no explanation or markdown.\n",
    "\"\"\"\n",
    "\n",
    "    # Load the Ollama model\n",
    "    llm = ChatOllama(model=llm_model_name)\n",
    "\n",
    "    # Create and send the prompt\n",
    "    messages = [\n",
    "        SystemMessage(content=system_prompt.strip()),\n",
    "        HumanMessage(content=user_input.strip())\n",
    "    ]\n",
    "    response = llm.invoke(messages)\n",
    "\n",
    "    # Validate using Pydantic\n",
    "    try:\n",
    "        return schema.parse_raw(response.content)\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Failed to parse model output: {e}\\nRaw Output:\\n{response.content}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62e4807-73d9-4e27-af95-f67de0fbd34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    allowed_banks = [\"JP Morgan Chase\", \"Bank of America\", \"Citigroup\", \"Wells Fargo\"]\n",
    "    allowed_metrics = [\"EarningsPerShare\", \"NetIncome\", \"TotalRevenue\", \"ReturnOnEquity\"]\n",
    "\n",
    "    user_input = \"I want a table comparing EPS and Net income of JPMC and BOA for Q1 2025\"\n",
    "\n",
    "    result = parse_with_chatollama(\n",
    "        llm_model_name=\"llama3\",  # Replace with your loaded Ollama model name\n",
    "        user_input=user_input,\n",
    "        schema=ParsedRequest,\n",
    "        allowed_banks=allowed_banks,\n",
    "        allowed_metrics=allowed_metrics\n",
    "    )\n",
    "\n",
    "    print(result.json(indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23c23e5-28d2-4eed-9d5e-c6118c442425",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Validate using Pydantic\n",
    "try:\n",
    "    raw = response.content.strip()\n",
    "\n",
    "    # Optional: clean triple backticks if LLM returns markdown\n",
    "    if \"```\" in raw:\n",
    "        import re\n",
    "        match = re.search(r\"```(?:json)?\\s*(\\{.*?\\})\\s*```\", raw, re.DOTALL)\n",
    "        if match:\n",
    "            raw = match.group(1)\n",
    "\n",
    "    # Step 1: Convert JSON string to Python dict\n",
    "    parsed_dict = json.loads(raw)\n",
    "\n",
    "    # Step 2: Validate and convert into a Pydantic object\n",
    "    parsed_model = schema.parse_obj(parsed_dict)\n",
    "\n",
    "    # Step 3: Return it (now it has `.model_dump_json()` etc.)\n",
    "    return parsed_model\n",
    "\n",
    "except Exception as e:\n",
    "    raise ValueError(f\"Failed to parse model output: {e}\\nRaw Output:\\n{response.content}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

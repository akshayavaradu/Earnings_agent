{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "10aae7a8-fcc1-4a06-91af-c167f8f98b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Type, Literal \n",
    "from pydantic import BaseModel\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "import json\n",
    "\n",
    "# ---------------------------\n",
    "# 1. Define the Pydantic Schema\n",
    "# ---------------------------\n",
    "class ParsedRequest_intent(BaseModel):\n",
    "    intent: str                 \n",
    " \n",
    "\n",
    "# ---------------------------\n",
    "# 2. Function to Use ChatOllama with Pydantic Schema\n",
    "# ---------------------------\n",
    "def intent(\n",
    "    llm_model_name: str,\n",
    "    user_input: str,\n",
    "    schema: Type[BaseModel]\n",
    "    \n",
    ") -> BaseModel:\n",
    "    system_prompt = \"\"\"You are a expert in classifying questions into 2 categories. The 2 categories are exact question , needs_clarification. A question is marked as exact if it has concrete details in 3 categories - company name, quarter & Year , metrics to be analysed. It is needs_clarification if the user uses words like analyse, in detail , research, elaborate or if the user doesn't provide specific metrics or company name or year & quarter to be analysed . give the output in JSON format srtictly . JSON has one key and it is called intent . For example ) {\"intent\": \"exact\"}\"\"\"\n",
    "    # Load the Ollama model\n",
    "    llm = ChatOllama(model=llm_model_name)\n",
    "\n",
    "    # Create and send the prompt\n",
    "    messages = [\n",
    "        SystemMessage(content=system_prompt.strip()),\n",
    "        HumanMessage(content=user_input.strip())\n",
    "    ]\n",
    "    response = llm.invoke(messages)\n",
    "\n",
    "    # Validate using Pydantic\n",
    "    try:\n",
    "        raw = response.content.strip()\n",
    "    \n",
    "        # Optional: clean triple backticks if LLM returns markdown\n",
    "        if \"```\" in raw:\n",
    "            import re\n",
    "            match = re.search(r\"```(?:json)?\\s*(\\{.*?\\})\\s*```\", raw, re.DOTALL)\n",
    "            if match:\n",
    "                raw = match.group(1)\n",
    "    \n",
    "        # Step 1: Convert JSON string to Python dict\n",
    "        parsed_dict = json.loads(raw)\n",
    "    \n",
    "        # Step 2: Validate and convert into a Pydantic object\n",
    "        parsed_model = schema.model_validate(parsed_dict)\n",
    "    \n",
    "        # Step 3: Return it (now it has `.model_dump_json()` etc.)\n",
    "        return parsed_model\n",
    "\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Failed to parse model output: {e}\\nRaw Output:\\n{response.content}\")\n",
    "\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7e69aa7c-13a7-4fde-bd26-1312c0278345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"intent\":\"exact\"}\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "user_input = \"Extract the net revenue of citi bank in 2025Q1 \"\n",
    "\n",
    "result = intent(\n",
    "    llm_model_name=\"qwen2.5:7b\",  # Replace with your loaded Ollama model name\n",
    "    user_input=user_input,\n",
    "    schema=ParsedRequest_intent\n",
    ")\n",
    "\n",
    "print(result.model_dump_json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "96681656-38b2-4386-b34a-e0bffc20f9d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='<think>\\nOkay, the user wants to extract the net revenue of Citigroup in 2025Q1. Let me start by checking the company name. They mentioned \"Citi Bank,\" which I need to map to the official name. From the list, \"Citigroup\" is the correct one. Next, the quarters. The user specified 2025Q1, so I should include the previous two quarters: 2024Q4 and 2024Q3. For metrics, they asked for net revenue, which is TotalRevenue. The required metrics are TotalRevenue, EarningsPerShare, NetIncome, and ReturnOnEquity. Since the user only mentioned net revenue, I\\'ll include that and add the other three as they are important for analysis. The years are 2025, so the quarters are 2025Q1, 2024Q4, 2024Q3. I need to make sure all the metrics are included as per the rules. Let me structure the final answer with these details.\\n</think>\\n\\nExtract the TotalRevenue, EarningsPerShare, NetIncome, and ReturnOnEquity for Citigroup in 2025Q1, 2024Q4, and 2024Q3.' additional_kwargs={} response_metadata={'model': 'qwen3:4b', 'created_at': '2025-06-28T14:01:13.2398203Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 72511580600, 'load_duration': 145513700, 'prompt_eval_count': 296, 'prompt_eval_duration': 16468475900, 'eval_count': 275, 'eval_duration': 55889891500} id='run--3d3b00b7-647d-49a5-b63c-2706b679cd27-0'\n"
     ]
    }
   ],
   "source": [
    "def vague (model,question,allowed_banks,allowed_metrics):\n",
    "    prompt=f\"\"\"You are an expert in elaborating and writing explicit questions. Expand the user provided vague question to include more detail along 3 dimensions. Company names , metrics, quarters&Years \n",
    "            ---------\n",
    "            Follow these instructions :\n",
    "            1. If the user doesn't mention any bank, assume company name as Wells Fargo\n",
    "            2. If the user doesn't mention quarter or years, assume 1Q2025, 4Q2024, 3Q2024\n",
    "            3. If the user doesn't provide any metrics  - assume it as Net Income, Earnings per share and total revenue \n",
    "            4. Add any additional metrics that you think will be important for senior leadership of a finance company to analyse reports \n",
    "            5. Just provide the final output without including the rationale part\n",
    "            ----------\n",
    "            Rules:\n",
    "            - Map any abbreviation or alias to official bank names from this list: {json.dumps(allowed_banks)}\n",
    "            - Extract all mentioned quarters in \"1Q2025\" format. Include the previous 2 quarters for each.\n",
    "            - Extract only metrics listed here: {json.dumps(allowed_metrics)}.\n",
    "            ----------\n",
    "            \"\"\"\n",
    "    llm=ChatOllama (model=model)\n",
    "    messages = [\n",
    "        SystemMessage(content=prompt.strip()),\n",
    "        HumanMessage(content=question.strip())\n",
    "    ]\n",
    "    response = llm.invoke(messages)\n",
    "    return response\n",
    "    \n",
    "allowed_banks = [\"JP Morgan Chase\", \"Bank of America\", \"Citigroup\", \"Wells Fargo\"]\n",
    "allowed_metrics = [\"EarningsPerShare\", \"NetIncome\", \"TotalRevenue\", \"ReturnOnEquity\"]\n",
    "\n",
    "user_input = \"Extract the net revenue of citi bank in 2025Q1\"\n",
    "\n",
    "result = vague(\n",
    "    model=\"qwen3:4b\",  # Replace with your loaded Ollama model name\n",
    "    question=user_input,\n",
    "    allowed_banks=allowed_banks,\n",
    "    allowed_metrics=allowed_metrics\n",
    ")\n",
    "print (result)\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bbc6b545-982e-4d35-a5a7-cc9147aa5a1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<think>\n",
       "Okay, the user wants to extract the net revenue of Citigroup in 2025Q1. Let me start by checking the company name. They mentioned \"Citi Bank,\" which I need to map to the official name. From the list, \"Citigroup\" is the correct one. Next, the quarters. The user specified 2025Q1, so I should include the previous two quarters: 2024Q4 and 2024Q3. For metrics, they asked for net revenue, which is TotalRevenue. The required metrics are TotalRevenue, EarningsPerShare, NetIncome, and ReturnOnEquity. Since the user only mentioned net revenue, I'll include that and add the other three as they are important for analysis. The years are 2025, so the quarters are 2025Q1, 2024Q4, 2024Q3. I need to make sure all the metrics are included as per the rules. Let me structure the final answer with these details.\n",
       "</think>\n",
       "\n",
       "Extract the TotalRevenue, EarningsPerShare, NetIncome, and ReturnOnEquity for Citigroup in 2025Q1, 2024Q4, and 2024Q3."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML, Markdown \n",
    "Markdown(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e489598d-5b18-47f7-8b96-9004cbee980d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7d531fb2-1f3d-45c9-841b-2ef21eacb4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Type, Literal \n",
    "from pydantic import BaseModel\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "import json\n",
    "\n",
    "# ---------------------------\n",
    "# 1. Define the Pydantic Schema\n",
    "# ---------------------------\n",
    "class ParsedRequest(BaseModel):\n",
    "                 \n",
    "    banks: List[str]            # Must match allowed_banks\n",
    "    quarters: List[str]         # e.g., \"1Q2025\", \"4Q2024\"\n",
    "    metrics: List[str]          # Must match allowed_metrics\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# 2. Function to Use ChatOllama with Pydantic Schema\n",
    "# ---------------------------\n",
    "def parse_with_chatollama(\n",
    "        llm_model_name: str,\n",
    "        user_input: str,\n",
    "        schema: Type[BaseModel],\n",
    "        allowed_banks: List[str],\n",
    "        allowed_metrics: List[str]\n",
    "    ) -> BaseModel:\n",
    "    system_prompt = f\"\"\"\n",
    "You are a financial assistant. Your task is to extract structured information from user input and return it in the following JSON format:\n",
    "\n",
    "{{\n",
    "  \n",
    "  \"banks\": [valid bank names],\n",
    "  \"quarters\": [\"1Q2025\", \"4Q2024\", \"3Q2024\"],\n",
    "  \"metrics\": [valid metric keys]\n",
    "}}\n",
    "\n",
    "Rules:\n",
    "- Map any abbreviation or alias to official bank names from this list: {json.dumps(allowed_banks)}\n",
    "- Extract all mentioned quarters in \"1Q2025\" format. Include the previous 2 quarters for each.\n",
    "- Extract only metrics listed here: {json.dumps(allowed_metrics)}.\n",
    "- Output only the JSON structure as shown above, no explanation or markdown.\n",
    "\"\"\"\n",
    "\n",
    "    # Load the Ollama model\n",
    "    llm = ChatOllama(model=llm_model_name)\n",
    "\n",
    "    # Create and send the prompt\n",
    "    messages = [\n",
    "        SystemMessage(content=system_prompt.strip()),\n",
    "        HumanMessage(content=user_input.strip())\n",
    "    ]\n",
    "    response = llm.invoke(messages)\n",
    "\n",
    "    # Validate using Pydantic\n",
    "    try:\n",
    "        raw = response.content.strip()\n",
    "    \n",
    "        # Optional: clean triple backticks if LLM returns markdown\n",
    "        if \"```\" in raw:\n",
    "            import re\n",
    "            match = re.search(r\"```(?:json)?\\s*(\\{.*?\\})\\s*```\", raw, re.DOTALL)\n",
    "            if match:\n",
    "                raw = match.group(1)\n",
    "    \n",
    "        # Step 1: Convert JSON string to Python dict\n",
    "        parsed_dict = json.loads(raw)\n",
    "    \n",
    "        # Step 2: Validate and convert into a Pydantic object\n",
    "        parsed_model = schema.model_validate(parsed_dict)\n",
    "    \n",
    "        # Step 3: Return it (now it has `.model_dump_json()` etc.)\n",
    "        return parsed_model\n",
    "\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Failed to parse model output: {e}\\nRaw Output:\\n{response.content}\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c62e4807-73d9-4e27-af95-f67de0fbd34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"banks\":[\"Citigroup\"],\"quarters\":[\"1Q2025\",\"4Q2024\",\"3Q2024\"],\"metrics\":[\"NetIncome\"]}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "allowed_banks = [\"JP Morgan Chase\", \"Bank of America\", \"Citigroup\", \"Wells Fargo\"]\n",
    "allowed_metrics = [\"EarningsPerShare\", \"NetIncome\", \"TotalRevenue\", \"ReturnOnEquity\"]\n",
    "\n",
    "user_input = \"Extract the net revenue of citi bank in 2025Q1\"\n",
    "\n",
    "result = parse_with_chatollama(\n",
    "    llm_model_name=\"qwen2.5:7b\",  # Replace with your loaded Ollama model name\n",
    "    user_input=user_input,\n",
    "    schema=ParsedRequest,\n",
    "    allowed_banks=allowed_banks,\n",
    "    allowed_metrics=allowed_metrics\n",
    ")\n",
    "\n",
    "print(result.model_dump_json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb26f2e4-1d7e-4a48-beb5-c3480187aaa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Akshaya V\\git\\Earnings research\\Earnings_agent\\PublicReportResearch-main\\docs\n",
      "['boa_ppt_2024_q2.pdf', 'boa_ppt_2024_q3.pdf', 'boa_ppt_2024_q4.pdf', 'boa_ppt_2025_q1.pdf', 'boa_result_2025_q1.pdf', 'citi_result_2024_q1.pdf', 'citi_result_2024_q2.pdf', 'citi_result_2024_q3.pdf', 'citi_result_2024_q4.pdf', 'citi_result_2025_q1.pdf']\n",
      "C:\\Users\\Akshaya V\\git\\Earnings research\\Earnings_agent\\PublicReportResearch-main\\docs\\boa_ppt_2024_q2.pdf\n",
      "C:\\Users\\Akshaya V\\git\\Earnings research\\Earnings_agent\\PublicReportResearch-main\\docs\\boa_ppt_2024_q2.pdf\n",
      "C:\\Users\\Akshaya V\\git\\Earnings research\\Earnings_agent\\PublicReportResearch-main\\docs\\boa_ppt_2024_q3.pdf\n",
      "C:\\Users\\Akshaya V\\git\\Earnings research\\Earnings_agent\\PublicReportResearch-main\\docs\\boa_ppt_2024_q4.pdf\n",
      "C:\\Users\\Akshaya V\\git\\Earnings research\\Earnings_agent\\PublicReportResearch-main\\docs\\boa_ppt_2025_q1.pdf\n",
      "C:\\Users\\Akshaya V\\git\\Earnings research\\Earnings_agent\\PublicReportResearch-main\\docs\\boa_result_2025_q1.pdf\n",
      "C:\\Users\\Akshaya V\\git\\Earnings research\\Earnings_agent\\PublicReportResearch-main\\docs\\citi_result_2024_q1.pdf\n",
      "C:\\Users\\Akshaya V\\git\\Earnings research\\Earnings_agent\\PublicReportResearch-main\\docs\\citi_result_2024_q2.pdf\n",
      "C:\\Users\\Akshaya V\\git\\Earnings research\\Earnings_agent\\PublicReportResearch-main\\docs\\citi_result_2024_q3.pdf\n",
      "C:\\Users\\Akshaya V\\git\\Earnings research\\Earnings_agent\\PublicReportResearch-main\\docs\\citi_result_2024_q4.pdf\n",
      "C:\\Users\\Akshaya V\\git\\Earnings research\\Earnings_agent\\PublicReportResearch-main\\docs\\citi_result_2025_q1.pdf\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "dic = r'C:\\Users\\Akshaya V\\git\\Earnings research\\Earnings_agent\\PublicReportResearch-main'\n",
    "full_path = os.path.join(dic, 'docs')\n",
    "\n",
    "print(full_path)\n",
    "print(os.listdir(full_path))\n",
    "print(os.path.join(full_path,os.listdir(full_path)[0]))\n",
    "for i in os.listdir(full_path):\n",
    "    print(os.path.join(full_path,i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f23c23e5-28d2-4eed-9d5e-c6118c442425",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdfminer.high_level import extract_pages\n",
    "from pdfminer.layout import LTTextBox, LTTextLine\n",
    "import re\n",
    "\n",
    "def is_natural_language(text):\n",
    "    # Must contain at least one sentence (simple heuristic)\n",
    "    return bool(re.search(r\"[A-Za-z]{4,}.*\\.\", text)) and not is_table_like(text)\n",
    "\n",
    "def is_table_like(text):\n",
    "    lines = text.strip().splitlines()\n",
    "    if len(lines) < 2:\n",
    "        return False\n",
    "\n",
    "    table_like = 0\n",
    "    for line in lines:\n",
    "        tokens = line.strip().split()\n",
    "        num_tokens = len(tokens)\n",
    "        numbers = len([t for t in tokens if re.fullmatch(r\"[\\d,.%$]+\", t)])\n",
    "        symbols = len([t for t in tokens if re.fullmatch(r\"[\\d,.%$O/(U)-]+\", t)])\n",
    "\n",
    "        if num_tokens >= 3 and numbers / num_tokens > 0.5:\n",
    "            table_like += 1\n",
    "        elif len(re.findall(r\"\\$\\s?\\d\", line)) > 1:  # multiple dollar values\n",
    "            table_like += 1\n",
    "        elif len(re.findall(r\"\\d{2,},\", line)) > 1:\n",
    "            table_like += 1\n",
    "\n",
    "    return table_like / len(lines) > 0.4\n",
    "\n",
    "def extract_text_excluding_tables(pdf_path):\n",
    "    final_text = []\n",
    "\n",
    "    for page_layout in extract_pages(pdf_path):\n",
    "        for element in page_layout:\n",
    "            if isinstance(element, (LTTextBox, LTTextLine)):\n",
    "                text = element.get_text().strip()\n",
    "                if text and is_natural_language(text):\n",
    "                    final_text.append(text)\n",
    "\n",
    "    return \"\\n\\n\".join(final_text).strip()\n",
    "\n",
    "# for pdf in os.listdir(full_path):\n",
    "#     print(pdf)\n",
    "#     text=\"\"\n",
    "#     text =f\"<{pdf}>\"\n",
    "#     clean_text = extract_text_excluding_tables(os.path.join(full_path,pdf))\n",
    "#     clean_text=text+clean_text\n",
    "#     text =f\"</{pdf}\"\n",
    "#     text=clean_text+text\n",
    "#     #print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98f1eb87-e6dc-4d55-8d70-257969e573a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_filename_metadata(filename: str):\n",
    "    name = os.path.splitext(os.path.basename(filename))[0]\n",
    "    parts = name.split(\"_\")\n",
    "    bank_map = {\n",
    "        \"jpm\": \"JP Morgan Chase\",\n",
    "        \"boa\": \"Bank of America\",\n",
    "        \"citi\": \"Citigroup\",\n",
    "        \"gs\": \"Goldman Sachs\",\n",
    "        \"ms\": \"Morgan Stanley\",\n",
    "    }\n",
    "    bank_code = parts[0].lower()\n",
    "    quarter = parts[1].upper() if len(parts) > 1 else \"UNKNOWN\"\n",
    "    bank = bank_map.get(bank_code, bank_code.upper())\n",
    "    return bank, quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15e77f7a-d954-41ef-b091-901fa5b8217c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParsedRequest(BaseModel):\n",
    "    intent: str\n",
    "    banks: List[str]\n",
    "    quarters: List[str]\n",
    "    metrics: List[str]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ca0acfb-fb2a-40f4-bc27-642c4e23581c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chunks_with_ollama(text: str, metadata: dict = None):\n",
    "    embedder = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "    chunker = SemanticChunker(embeddings=embedder, min_chunk_size=2000)\n",
    "\n",
    "    doc = Document(page_content=text, metadata=metadata or {})\n",
    "    return chunker.split_documents([doc])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aece91db-1387-4705-be3c-2a94c2589cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_chunks(chunks, parsed_query: ParsedRequest, top_k=5):\n",
    "    embedder = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "    vectorstore = FAISS.from_documents(chunks, embedder)\n",
    "\n",
    "    query_text = (\n",
    "        f\"Find information about {', '.join(parsed_query.metrics)} \"\n",
    "        f\"for banks like {', '.join(parsed_query.banks)} \"\n",
    "        f\"during quarters such as {', '.join(parsed_query.quarters)}\"\n",
    "    )\n",
    "\n",
    "    return vectorstore.similarity_search(query_text, k=top_k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b4b662f-68c7-4ddb-88a1-0a9c2a909d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerank_with_chatollama(chunks, parsed_query: ParsedRequest):\n",
    "    llm = ChatOllama(model=\"llama3.2:3b\")\n",
    "    context = \"\\n\\n\".join([chunk.page_content for chunk in chunks])\n",
    "\n",
    "    prompt = (\n",
    "        f\"You are a financial analyst assistant.\\n\\n\"\n",
    "        f\"Query:\\n{parsed_query.model_dump_json(indent=2)}\\n\\n\"\n",
    "        f\"Extracted text:\\n{context}\\n\\n\"\n",
    "        f\"Please summarize the relevant details in a table or paragraph based on the query intent.\"\n",
    "    )\n",
    "\n",
    "    response = llm([HumanMessage(content=prompt)])\n",
    "    return response.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547d9e7b-668e-4966-835e-c3ea84527acc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb54916c-48ff-43cb-b285-de3faa37c9d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Processing: boa_ppt_2024_q2.pdf\n",
      "ðŸ“„ Processing: boa_ppt_2024_q3.pdf\n",
      "ðŸ“„ Processing: boa_ppt_2024_q4.pdf\n",
      "ðŸ“„ Processing: boa_ppt_2025_q1.pdf\n",
      "ðŸ“„ Processing: boa_result_2025_q1.pdf\n",
      "ðŸ“„ Processing: citi_result_2024_q1.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot set gray non-stroke color because /'P43' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P45' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P46' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P61' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P62' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P66' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P67' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P71' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P72' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P78' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P79' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P83' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P84' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P88' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P89' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P124' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P125' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P132' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P133' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P137' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P139' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P147' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P148' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P150' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P151' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P153' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P154' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P158' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P159' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P161' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P162' is an invalid float value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Processing: citi_result_2024_q2.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot set gray non-stroke color because /'P39' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P41' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P42' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P56' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P57' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P63' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P64' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P68' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P69' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P75' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P76' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P80' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P81' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P87' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P88' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P119' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P120' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P127' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P128' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P132' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P134' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P142' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P143' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P145' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P146' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P148' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P149' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P154' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P155' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P157' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P158' is an invalid float value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Processing: citi_result_2024_q3.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot set gray non-stroke color because /'P40' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P42' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P43' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P47' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P48' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P52' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P53' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P57' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P58' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P64' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P65' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P69' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P70' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P74' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P75' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P89' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P90' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P97' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P98' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P100' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P102' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P106' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P107' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P109' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P110' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P112' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P113' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P117' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P118' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P120' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P121' is an invalid float value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Processing: citi_result_2024_q4.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot set gray non-stroke color because /'P45' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P47' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P48' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P49' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P53' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P54' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P55' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P60' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P61' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P62' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P67' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P68' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P70' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P76' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P77' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P78' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P82' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P83' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P85' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P89' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P90' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P92' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P106' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P107' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P110' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P111' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P115' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P117' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P120' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P121' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P125' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P126' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P128' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P129' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P131' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P132' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P134' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P135' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P139' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P140' is an invalid float value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Processing: citi_result_2025_q1.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot set gray non-stroke color because /'P40' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P42' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P43' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P49' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P50' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P54' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P55' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P59' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P60' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P66' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P67' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P73' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P74' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P78' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P79' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P93' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P94' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P102' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P103' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P105' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P107' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P111' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P112' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P114' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P115' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P117' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P118' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P120' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P121' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P125' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P126' is an invalid float value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total Chunks Created: 99\n",
      "\n",
      "--- Chunk 1 ---\n",
      "Metadata: {'source': 'boa_ppt_2024_q2.pdf', 'bank': 'Bank of America', 'quarter': 'PPT'}\n",
      "Content preview: <Bank of America PPT>\n",
      "Lee McEntire \n",
      "Good morning. Welcome. Thank you for joining the call to review our second quarter results. Our earnings \n",
      "release documents are available on the Investor Relations section of the bankofamerica.com website, and \n",
      "they include the earnings presentation that we will m ...\n",
      "\n",
      "\n",
      "--- Chunk 2 ---\n",
      "Metadata: {'source': 'boa_ppt_2024_q2.pdf', 'bank': 'Bank of America', 'quarter': 'PPT'}\n",
      "Content preview: We're not complacent with the \n",
      "success you see on this page. We continue to strategically invest in our core businesses. A few examples. While we have the leading retail deposit share in America, we continue to invest and have \n",
      "opened 11 new financial centers this quarter in the first half of the ye ...\n",
      "\n",
      "\n",
      "--- Chunk 3 ---\n",
      "Metadata: {'source': 'boa_ppt_2024_q2.pdf', 'bank': 'Bank of America', 'quarter': 'PPT'}\n",
      "Content preview: A couple of things to note here. First, we've noted for several quarters that the second \n",
      "quarter NII would be the trough for this rate cycle. We expect NII to grow in the third quarter and fourth \n",
      "quarter this year. Alastair is going to provide you some points in detail about the path forward. One  ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from pdfminer.high_level import extract_pages\n",
    "from pdfminer.layout import LTTextBox, LTTextLine\n",
    "import re\n",
    "import json\n",
    "from typing import List\n",
    "from pydantic import BaseModel\n",
    "from langchain_core.documents import Document\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain.schema import HumanMessage\n",
    "import os\n",
    "import re\n",
    "from glob import glob\n",
    "from pdfminer.high_level import extract_pages\n",
    "from pdfminer.layout import LTTextBox, LTTextLine\n",
    "full_path = r\"C:\\Users\\Akshaya V\\git\\Earnings research\\Earnings_agent\\PublicReportResearch-main\\docs\"\n",
    "\n",
    "all_chunks = []\n",
    "\n",
    "for pdf in os.listdir(full_path):\n",
    "    if not pdf.lower().endswith(\".pdf\"):\n",
    "        continue\n",
    "\n",
    "    pdf_path = os.path.join(full_path, pdf)\n",
    "    print(f\"ðŸ“„ Processing: {pdf}\")\n",
    "\n",
    "    bank, quarter = parse_filename_metadata(pdf)\n",
    "    clean_text = extract_text_excluding_tables(pdf_path)\n",
    "\n",
    "    # Wrap in custom tags for traceability\n",
    "    tagged_text = f\"<{bank} {quarter}>\\n{clean_text}\\n</{bank} {quarter}>\"\n",
    "\n",
    "    # Metadata\n",
    "    metadata = {\n",
    "        \"source\": pdf,\n",
    "        \"bank\": bank,\n",
    "        \"quarter\": quarter\n",
    "    }\n",
    "\n",
    "    # Chunk with metadata\n",
    "    chunks = create_chunks_with_ollama(tagged_text, metadata)\n",
    "    all_chunks.extend(chunks)\n",
    "\n",
    "# âœ… Print preview\n",
    "print(f\"\\nTotal Chunks Created: {len(all_chunks)}\")\n",
    "for i, chunk in enumerate(all_chunks[:3]):\n",
    "    print(f\"\\n--- Chunk {i+1} ---\")\n",
    "    print(\"Metadata:\", chunk.metadata)\n",
    "    print(\"Content preview:\", chunk.page_content[:300], \"...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "255a973e-b744-4644-9474-ac7ab646d102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a summary of the relevant details in a paragraph:\n",
      "\n",
      "Bank of America reported its quarterly earnings, with net income of $1.9 billion and revenue of $6.0 billion. The company saw an increase in non-interest expense by 6% driven by investments in technology and operations. However, the revenue was flat due to gains from leveraged finance positions offsetting lower Net Interest Income (NII). Bank of America also reported its market share and relationships with major corporations, including 78% coverage of the Global Fortune 500 and 95% coverage of the U.S. corporate banking market.\n",
      "\n",
      "Additionally, the company announced plans to expand its network in key markets, focusing on building out branches in cities like Columbus, where it already has a significant presence. This will allow for more efficient operations and better customer engagement, particularly in terms of digital services.\n"
     ]
    }
   ],
   "source": [
    "structured_query = '''{\n",
    "    \"intent\": \"in-depth\",\n",
    "    \"banks\": [\"JP Morgan Chase\", \"Bank of America\"],\n",
    "    \"quarters\": [\"1Q2025\", \"4Q2024\", \"3Q2024\"],\n",
    "    \"metrics\": [\"EarningsPerShare\", \"NetIncome\"]\n",
    "}'''\n",
    "\n",
    "parsed_query = ParsedRequest.model_validate(json.loads(structured_query))\n",
    "\n",
    "# Search top relevant chunks based on user's intent\n",
    "matched_chunks = search_chunks(all_chunks, parsed_query, top_k=5)\n",
    "\n",
    "# Generate final answer with LLM (LLaMA 3.2)\n",
    "final_answer = rerank_with_chatollama(matched_chunks, parsed_query)\n",
    "print(final_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b6f01ca-e599-44dd-88a3-02352c3f2534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided text, here is a summary of the relevant details:\n",
      "\n",
      "**Bank Performance**\n",
      "\n",
      "* Bank of America (BofA) reported $6.0 billion in revenue, net of interest expense, for 2Q2025.\n",
      "* Net income was $1.9 billion.\n",
      "* The bank's efficiency ratio improved due to increased operating leverage from NII growth.\n",
      "\n",
      "**Business Highlights**\n",
      "\n",
      "* BofA maintained its position as the number one investment banking firm and won the \"U.S. Corporate Banking & Best Bank Award\".\n",
      "* The bank has relationships with 78% of the Global Fortune 500 and 95% of the U.S. Global Fortune 500.\n",
      "* BofA's average deposits were $100 million per branch, exceeding expectations due to density and capacity.\n",
      "\n",
      "**Future Plans**\n",
      "\n",
      "* The bank aims to expand its presence in top markets across the country to cover the American population efficiently and effectively.\n",
      "* BofA is focusing on building a network in key locations, such as Columbus, Ohio, rather than expanding rapidly.\n",
      "* The bank expects to continue growing organically and returning capital to shareholders.\n",
      "\n",
      "**Financial Performance**\n",
      "\n",
      "| Metric | Value |\n",
      "| --- | --- |\n",
      "| Revenue (net of interest) | $6.0 billion |\n",
      "| Net Income | $1.9 billion |\n",
      "| Earnings Per Share | $0.81 |\n",
      "| Efficiency Ratio | Improved due to NII growth |\n",
      "\n",
      "Overall, BofA reported strong financial performance in 2Q2025, with revenue and net income growth driven by increased operating leverage from non-interest income (NII) growth. The bank's expansion plans focus on building a network of branches in key locations, rather than rapid expansion.\n"
     ]
    }
   ],
   "source": [
    "structured_query = result.model_dump_json()\n",
    "\n",
    "parsed_query = ParsedRequest.model_validate(json.loads(structured_query))\n",
    "\n",
    "# Search top relevant chunks based on user's intent\n",
    "matched_chunks = search_chunks(all_chunks, parsed_query, top_k=5)\n",
    "\n",
    "# Generate final answer with LLM (LLaMA 3.2)\n",
    "final_answer = rerank_with_chatollama(matched_chunks, parsed_query)\n",
    "print(final_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a281d4a-5ea2-4770-8f49-07d304114c21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbb4942-e7a9-4622-9701-ff629bc2a04f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "11f1138b-1712-4a81-8773-d8dedb544eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-30 19:20:03,468 - INFO - Starting data download for 2 banks from 2019-01-01 to 2025-12-31\n",
      "2025-06-30 19:20:03,469 - INFO - Extracting 52 financial metrics\n",
      "2025-06-30 19:20:03,470 - INFO - Processing 1/2: JPMorgan Chase & Co.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEC Bank Earnings Data Extractor - Enhanced Version\n",
      "==================================================\n",
      "Downloading data from 2019-01-01 to 2025-12-31\n",
      "Target banks: 2\n",
      "Target metrics: 52 (prioritized by stakeholder importance)\n",
      "\n",
      "Metric Priority Tiers:\n",
      "TIER 1 (1-7): Core Profitability & Performance\n",
      "TIER 2 (8-15): Capital & Balance Sheet Strength\n",
      "TIER 3 (16-21): Risk Management & Credit Quality\n",
      "TIER 4 (22-28): Income Statement Detail\n",
      "TIER 5 (29-33): Operational Efficiency\n",
      "TIER 6 (34-38): Growth & Market Metrics\n",
      "TIER 7 (39-43): Trading & Investment Banking\n",
      "TIER 8 (44-48): Regulatory & Capital Management\n",
      "TIER 9 (49-50): Additional Balance Sheet Items\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-30 19:20:48,033 - INFO - Extracted 25 records for JPMorgan Chase & Co.\n",
      "2025-06-30 19:20:48,136 - INFO - Processing 2/2: Bank of America Corp\n",
      "2025-06-30 19:21:32,187 - INFO - Extracted 25 records for Bank of America Corp\n",
      "2025-06-30 19:21:32,368 - INFO - Calculated derived financial metrics\n",
      "2025-06-30 19:21:32,383 - INFO - Successfully extracted 50 total records with 52 metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data extraction completed!\n",
      "Total records: 50\n",
      "Companies with data: 2\n",
      "Date range: 2019-03-31 00:00:00 to 2025-03-31 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-30 19:21:33,235 - INFO - Data saved to bank_earnings_data_2019-01-01_2025-12-31.xlsx\n",
      "2025-06-30 19:21:33,238 - INFO - Excel file contains 3 sheets: Bank_Earnings_Data, Summary, and Metrics_Dictionary\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data saved to: bank_earnings_data_2019-01-01_2025-12-31.xlsx\n",
      "\n",
      "Data Quality Summary:\n",
      "Data completeness: 41.1%\n",
      "Total possible data points: 2,600\n",
      "Actual data points extracted: 1,069\n",
      "\n",
      "Top 10 metrics by data availability:\n",
      " 1. NetIncome                   50 records (100.0%)\n",
      " 2. NetInterestIncome           50 records (100.0%)\n",
      " 3. ReturnOnEquity              50 records (100.0%)\n",
      " 4. ReturnOnAssets              50 records (100.0%)\n",
      " 5. ShareholdersEquity          50 records (100.0%)\n",
      " 6. EarningsPerShare            50 records (100.0%)\n",
      " 7. EarningsPerShareDiluted     50 records (100.0%)\n",
      " 8. TotalAssets                 50 records (100.0%)\n",
      " 9. TotalDeposits               50 records (100.0%)\n",
      "10. NonInterestIncome           50 records (100.0%)\n",
      "\n",
      "Sample data preview (Top 10 priority metrics):\n",
      "  Datetime                 CompanyName   NetIncome  TotalRevenue  NetInterestIncome ReturnOnEquity ReturnOnAssets  EarningsPerShare  EarningsPerShareDiluted   TotalAssets  ShareholdersEquity  TotalDeposits\n",
      "2019-03-31 Bank of America Corporation  7311000000  2.300400e+10        12375000000         2.7381       0.307551              0.71                     0.70 2377164000000        267010000000  1379337000000\n",
      "2019-06-30 Bank of America Corporation 14659000000  4.608800e+10        24564000000       5.401094       0.611839              1.45                     1.45 2395892000000        271408000000  1375093000000\n",
      "2019-09-30 Bank of America Corporation 20436000000  6.889500e+10        36751000000       7.614378        0.84226              2.02                     2.01 2426330000000        268387000000  1392836000000\n",
      "\n",
      "Metrics organized by priority tiers:\n",
      "\n",
      "TIER 1: Core Profitability & Performance:\n",
      "   1. NetIncome                      ( 50 records, 100.0%)\n",
      "   2. TotalRevenue                   ( 31 records,  62.0%)\n",
      "   3. NetInterestIncome              ( 50 records, 100.0%)\n",
      "   4. ReturnOnEquity                 ( 50 records, 100.0%)\n",
      "   5. ReturnOnAssets                 ( 50 records, 100.0%)\n",
      "   6. EarningsPerShare               ( 50 records, 100.0%)\n",
      "   7. EarningsPerShareDiluted        ( 50 records, 100.0%)\n",
      "\n",
      "TIER 2: Capital & Balance Sheet Strength:\n",
      "   8. TotalAssets                    ( 50 records, 100.0%)\n",
      "   9. ShareholdersEquity             ( 50 records, 100.0%)\n",
      "  10. TotalDeposits                  ( 50 records, 100.0%)\n",
      "  11. TotalLoans                     (  2 records,   4.0%)\n",
      "  12. BookValuePerShare              (  0 records,   0.0%)\n",
      "  13. TangibleBookValuePerShare      (  0 records,   0.0%)\n",
      "  14. Tier1CapitalRatio              (  0 records,   0.0%)\n",
      "  15. ProvisionForLoanLosses         (  4 records,   8.0%)\n",
      "\n",
      "TIER 3: Risk Management & Credit Quality:\n",
      "  16. AllowanceForLoanLosses         (  0 records,   0.0%)\n",
      "  17. NonPerformingLoans             (  0 records,   0.0%)\n",
      "  18. ChargeOffs                     (  0 records,   0.0%)\n",
      "  19. LoanLossReserveRatio           (  0 records,   0.0%)\n",
      "  20. NonPerformingAssetRatio        (  0 records,   0.0%)\n",
      "  21. InterestIncome                 ( 50 records, 100.0%)\n",
      "\n",
      "TIER 4: Income Statement Detail:\n",
      "  22. InterestExpense                ( 50 records, 100.0%)\n",
      "  23. NonInterestIncome              ( 50 records, 100.0%)\n",
      "  24. NonInterestExpense             ( 50 records, 100.0%)\n",
      "  25. OperatingExpenses              (  0 records,   0.0%)\n",
      "  26. PersonnelExpense               ( 50 records, 100.0%)\n",
      "  27. OccupancyExpense               ( 50 records, 100.0%)\n",
      "  28. EfficiencyRatio                ( 50 records, 100.0%)\n",
      "\n",
      "TIER 5: Operational Efficiency:\n",
      "  29. NetInterestMargin              (  0 records,   0.0%)\n",
      "  30. CostOfFunds                    (  0 records,   0.0%)\n",
      "  31. AssetTurnover                  (  0 records,   0.0%)\n",
      "  32. OperatingLeverage              (  0 records,   0.0%)\n",
      "  33. TotalRevenueGrowth             (  0 records,   0.0%)\n",
      "\n",
      "TIER 6: Growth & Market Metrics:\n",
      "  34. LoanGrowth                     (  0 records,   0.0%)\n",
      "  35. DepositGrowth                  (  0 records,   0.0%)\n",
      "  36. TangibleEquityRatio            (  0 records,   0.0%)\n",
      "  37. LeverageRatio                  (  0 records,   0.0%)\n",
      "  38. TradingRevenue                 ( 50 records, 100.0%)\n",
      "\n",
      "TIER 7: Trading & Investment Banking:\n",
      "  39. InvestmentBankingRevenue       ( 25 records,  50.0%)\n",
      "  40. TrustAndInvestmentFees         (  0 records,   0.0%)\n",
      "  41. ServiceCharges                 (  0 records,   0.0%)\n",
      "  42. CardRevenue                    (  0 records,   0.0%)\n",
      "  43. CommonEquityTier1Ratio         (  0 records,   0.0%)\n",
      "\n",
      "TIER 8: Regulatory & Capital Management:\n",
      "  44. TotalCapitalRatio              (  0 records,   0.0%)\n",
      "  45. RiskWeightedAssets             (  0 records,   0.0%)\n",
      "  46. LeverageCapitalRatio           (  0 records,   0.0%)\n",
      "  47. LiquidityRatio                 (  0 records,   0.0%)\n",
      "  48. TradingAssets                  ( 25 records,  50.0%)\n",
      "\n",
      "TIER 9: Additional Balance Sheet Items:\n",
      "  49. AvailableForSaleSecurities     ( 25 records,  50.0%)\n",
      "  50. HeldToMaturitySecurities       ( 25 records,  50.0%)\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "from typing import Dict, List, Optional\n",
    "import xml.etree.ElementTree as ET\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class SECBankDataExtractor:\n",
    "    def __init__(self, user_agent: str = \"akshayavaradu@gmail.com\"):\n",
    "        \"\"\"\n",
    "        Initialize the SEC data extractor\n",
    "        \n",
    "        Args:\n",
    "            user_agent: Required user agent for SEC API requests\n",
    "        \"\"\"\n",
    "        self.user_agent = user_agent\n",
    "        self.base_url = \"https://data.sec.gov\"\n",
    "        self.headers = {\n",
    "            'User-Agent': self.user_agent,\n",
    "            'Accept-Encoding': 'gzip, deflate',\n",
    "            'Host': 'data.sec.gov'\n",
    "        }\n",
    "        \n",
    "        # Top 20 US Banks by Assets (CIK numbers)\n",
    "        self.top_banks = {\n",
    "            'JPMorgan Chase & Co.': '0000019617',\n",
    "            'Bank of America Corp': '0000070858'\n",
    "            \n",
    "        }\n",
    "        \n",
    "        # Top 50 financial metrics prioritized by importance for banking stakeholders\n",
    "        # Order: Most critical metrics first (profitability, capital, risk) -> operational -> growth -> regulatory\n",
    "        self.target_metrics = [\n",
    "            # TIER 1: Core Profitability & Performance (Most Important)\n",
    "            'NetIncome',                           # Bottom line profitability\n",
    "            'TotalRevenue',                        # Top line revenue\n",
    "            'NetInterestIncome',                   # Core banking income\n",
    "            'ReturnOnEquity',                      # Key profitability ratio\n",
    "            'ReturnOnAssets',                      # Asset efficiency\n",
    "            'EarningsPerShare',                    # Shareholder value\n",
    "            'EarningsPerShareDiluted',             # Diluted EPS\n",
    "            \n",
    "            # TIER 2: Capital & Balance Sheet Strength\n",
    "            'TotalAssets',                         # Bank size/scale\n",
    "            'ShareholdersEquity',                  # Capital base\n",
    "            'TotalDeposits',                       # Funding base\n",
    "            'TotalLoans',                          # Core asset\n",
    "            'BookValuePerShare',                   # Per-share equity value\n",
    "            'TangibleBookValuePerShare',           # Tangible equity value\n",
    "            'Tier1CapitalRatio',                   # Regulatory capital\n",
    "            \n",
    "            # TIER 3: Risk Management & Credit Quality\n",
    "            'ProvisionForLoanLosses',              # Credit risk expense\n",
    "            'AllowanceForLoanLosses',              # Credit loss reserves\n",
    "            'NonPerformingLoans',                  # Problem assets\n",
    "            'ChargeOffs',                          # Realized losses\n",
    "            'LoanLossReserveRatio',                # Reserve coverage\n",
    "            'NonPerformingAssetRatio',             # Asset quality\n",
    "            \n",
    "            # TIER 4: Income Statement Detail\n",
    "            'InterestIncome',                      # Interest revenue\n",
    "            'InterestExpense',                     # Interest costs\n",
    "            'NonInterestIncome',                   # Fee income\n",
    "            'NonInterestExpense',                  # Operating expenses\n",
    "            'OperatingExpenses',                   # Total opex\n",
    "            'PersonnelExpense',                    # Staff costs\n",
    "            'OccupancyExpense',                    # Facility costs\n",
    "            \n",
    "            # TIER 5: Operational Efficiency\n",
    "            'EfficiencyRatio',                     # Cost efficiency\n",
    "            'NetInterestMargin',                   # Spread profitability\n",
    "            'CostOfFunds',                         # Funding cost\n",
    "            'AssetTurnover',                       # Asset utilization\n",
    "            'OperatingLeverage',                   # Operating efficiency\n",
    "            \n",
    "            # TIER 6: Growth & Market Metrics\n",
    "            'TotalRevenueGrowth',                  # Revenue growth\n",
    "            'LoanGrowth',                          # Loan portfolio growth\n",
    "            'DepositGrowth',                       # Deposit growth\n",
    "            'TangibleEquityRatio',                 # Tangible capital ratio\n",
    "            'LeverageRatio',                       # Financial leverage\n",
    "            \n",
    "            # TIER 7: Trading & Investment Banking\n",
    "            'TradingRevenue',                      # Trading income\n",
    "            'InvestmentBankingRevenue',            # IB fees\n",
    "            'TrustAndInvestmentFees',              # Wealth management\n",
    "            'ServiceCharges',                      # Service fees\n",
    "            'CardRevenue',                         # Credit card income\n",
    "            \n",
    "            # TIER 8: Regulatory & Capital Management\n",
    "            'CommonEquityTier1Ratio',              # CET1 ratio\n",
    "            'TotalCapitalRatio',                   # Total capital\n",
    "            'RiskWeightedAssets',                  # RWA\n",
    "            'LeverageCapitalRatio',                # Leverage ratio\n",
    "            'LiquidityRatio',                      # Liquidity position\n",
    "            \n",
    "            # TIER 9: Additional Balance Sheet Items\n",
    "            'TradingAssets',                       # Trading portfolio\n",
    "            'AvailableForSaleSecurities',          # AFS securities\n",
    "            'HeldToMaturitySecurities',            # HTM securities\n",
    "            'Goodwill',                            # Goodwill asset\n",
    "            'IntangibleAssets'                     # Other intangibles\n",
    "        ]\n",
    "    \n",
    "    def get_company_facts(self, cik: str) -> Optional[Dict]:\n",
    "        \"\"\"\n",
    "        Get company facts from SEC API\n",
    "        \n",
    "        Args:\n",
    "            cik: Company CIK number\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary containing company facts or None if error\n",
    "        \"\"\"\n",
    "        try:\n",
    "            url = f\"{self.base_url}/api/xbrl/companyfacts/CIK{cik.zfill(10)}.json\"\n",
    "            response = requests.get(url, headers=self.headers)\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                return response.json()\n",
    "            else:\n",
    "                logger.warning(f\"Failed to get company facts for CIK {cik}: {response.status_code}\")\n",
    "                return None\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error getting company facts for CIK {cik}: {str(e)}\")\n",
    "            return None\n",
    "    \n",
    "    def get_company_filings(self, cik: str, start_date: str, end_date: str) -> Optional[Dict]:\n",
    "        \"\"\"\n",
    "        Get company filings from SEC API\n",
    "        \n",
    "        Args:\n",
    "            cik: Company CIK number\n",
    "            start_date: Start date in YYYY-MM-DD format\n",
    "            end_date: End date in YYYY-MM-DD format\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary containing filings data or None if error\n",
    "        \"\"\"\n",
    "        try:\n",
    "            url = f\"{self.base_url}/api/xbrl/submissions/CIK{cik.zfill(10)}.json\"\n",
    "            response = requests.get(url, headers=self.headers)\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                data = response.json()\n",
    "                # Filter filings by date and form type\n",
    "                filings = []\n",
    "                recent_filings = data.get('filings', {}).get('recent', {})\n",
    "                \n",
    "                if recent_filings:\n",
    "                    for i in range(len(recent_filings.get('form', []))):\n",
    "                        form_type = recent_filings['form'][i]\n",
    "                        filing_date = recent_filings['filingDate'][i]\n",
    "                        \n",
    "                        if form_type in ['10-K', '10-Q'] and start_date <= filing_date <= end_date:\n",
    "                            filings.append({\n",
    "                                'form': form_type,\n",
    "                                'filingDate': filing_date,\n",
    "                                'accessionNumber': recent_filings['accessionNumber'][i],\n",
    "                                'reportDate': recent_filings.get('reportDate', [''])[i],\n",
    "                                'primaryDocument': recent_filings.get('primaryDocument', [''])[i]\n",
    "                            })\n",
    "                \n",
    "                return {'filings': filings}\n",
    "            else:\n",
    "                logger.warning(f\"Failed to get filings for CIK {cik}: {response.status_code}\")\n",
    "                return None\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error getting filings for CIK {cik}: {str(e)}\")\n",
    "            return None\n",
    "    \n",
    "    def extract_financial_metrics(self, company_facts: Dict, start_date: str, end_date: str) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Extract financial metrics from company facts\n",
    "        \n",
    "        Args:\n",
    "            company_facts: Company facts data from SEC API\n",
    "            start_date: Start date in YYYY-MM-DD format\n",
    "            end_date: End date in YYYY-MM-DD format\n",
    "            \n",
    "        Returns:\n",
    "            List of dictionaries containing extracted metrics\n",
    "        \"\"\"\n",
    "        metrics_data = []\n",
    "        \n",
    "        try:\n",
    "            facts = company_facts.get('facts', {})\n",
    "            us_gaap = facts.get('us-gaap', {})\n",
    "            dei = facts.get('dei', {})\n",
    "            \n",
    "            # Comprehensive GAAP tags mapping to our 50 target metrics\n",
    "            gaap_mapping = {\n",
    "                # TIER 1: Core Profitability & Performance\n",
    "                'NetIncome': ['NetIncomeLoss', 'ProfitLoss', 'NetIncomeLossAvailableToCommonStockholdersBasic', 'IncomeLossFromContinuingOperations'],\n",
    "                'TotalRevenue': ['Revenues', 'RevenueFromContractWithCustomerExcludingAssessedTax', 'InterestAndDividendIncomeOperating', 'TotalRevenues'],\n",
    "                'NetInterestIncome': ['InterestIncomeExpenseNet', 'NetInterestIncome', 'InterestIncomeExpenseAfterProvisionForLoanLoss'],\n",
    "                'ReturnOnEquity': ['ReturnOnAverageEquity', 'ReturnOnEquity'],\n",
    "                'ReturnOnAssets': ['ReturnOnAverageAssets', 'ReturnOnAssets'],\n",
    "                'EarningsPerShare': ['EarningsPerShareBasic', 'IncomeLossFromContinuingOperationsPerBasicShare'],\n",
    "                'EarningsPerShareDiluted': ['EarningsPerShareDiluted', 'IncomeLossFromContinuingOperationsPerDilutedShare'],\n",
    "                \n",
    "                # TIER 2: Capital & Balance Sheet Strength\n",
    "                'TotalAssets': ['Assets', 'AssetsCurrent', 'AssetsNoncurrent'],\n",
    "                'ShareholdersEquity': ['StockholdersEquity', 'StockholdersEquityIncludingPortionAttributableToNoncontrollingInterest', 'EquityAttributableToParent'],\n",
    "                'TotalDeposits': ['Deposits', 'DepositsTotal', 'InterestBearingDeposits', 'NoninterestBearingDeposits'],\n",
    "                'TotalLoans': ['LoansAndLeasesReceivableNetOfAllowance', 'LoansAndLeasesReceivableGross', 'LoansReceivableNet'],\n",
    "                'BookValuePerShare': ['BookValuePerShare', 'StockholdersEquityPerShare'],\n",
    "                'TangibleBookValuePerShare': ['TangibleBookValuePerShare'],\n",
    "                'Tier1CapitalRatio': ['Tier1CapitalRatio', 'CapitalAdequacyTier1CapitalRatio'],\n",
    "                \n",
    "                # TIER 3: Risk Management & Credit Quality\n",
    "                'ProvisionForLoanLosses': ['ProvisionForLoanAndLeaseLosses', 'ProvisionForCreditLosses', 'ProvisionForDoubtfulAccounts'],\n",
    "                'AllowanceForLoanLosses': ['AllowanceForLoanAndLeaseLosses', 'AllowanceForCreditLossesFinancingReceivables'],\n",
    "                'NonPerformingLoans': ['LoansAndLeasesReceivableNonaccrual', 'NonperformingLoans'],\n",
    "                'ChargeOffs': ['LoansAndLeasesReceivableChargeOffs', 'ChargeOffsLoansAndLeases'],\n",
    "                'LoanLossReserveRatio': ['LoanLossReserveRatio'],\n",
    "                'NonPerformingAssetRatio': ['NonperformingAssetRatio'],\n",
    "                \n",
    "                # TIER 4: Income Statement Detail\n",
    "                'InterestIncome': ['InterestAndFeeIncomeLoansAndLeases', 'InterestIncomeOperating', 'InterestAndDividendIncomeOperating', 'InterestIncomeLoansAndLeases'],\n",
    "                'InterestExpense': ['InterestExpense', 'InterestExpenseDeposits', 'InterestExpenseDebt', 'InterestExpenseBorrowings'],\n",
    "                'NonInterestIncome': ['NoninterestIncome', 'RevenuesExcludingInterestAndDividends', 'FeesAndCommissions'],\n",
    "                'NonInterestExpense': ['NoninterestExpense', 'OperatingExpenses', 'GeneralAndAdministrativeExpense'],\n",
    "                'OperatingExpenses': ['OperatingExpenses', 'CostsAndExpenses', 'OperatingCostsAndExpenses'],\n",
    "                'PersonnelExpense': ['LaborAndRelatedExpense', 'EmployeeRelatedExpense', 'SalariesAndWages'],\n",
    "                'OccupancyExpense': ['OccupancyNet', 'OccupancyAndEquipmentExpense'],\n",
    "                \n",
    "                # TIER 5: Operational Efficiency\n",
    "                'EfficiencyRatio': ['EfficiencyRatio'],\n",
    "                'NetInterestMargin': ['NetInterestMargin'],\n",
    "                'CostOfFunds': ['CostOfFunds'],\n",
    "                'AssetTurnover': ['AssetTurnover'],\n",
    "                'OperatingLeverage': ['OperatingLeverage'],\n",
    "                \n",
    "                # TIER 6: Growth & Market Metrics\n",
    "                'TotalRevenueGrowth': ['RevenueGrowthRate'],\n",
    "                'LoanGrowth': ['LoanGrowthRate'],\n",
    "                'DepositGrowth': ['DepositGrowthRate'],\n",
    "                'TangibleEquityRatio': ['TangibleEquityRatio'],\n",
    "                'LeverageRatio': ['LeverageRatio', 'DebtToEquityRatio'],\n",
    "                \n",
    "                # TIER 7: Trading & Investment Banking\n",
    "                'TradingRevenue': ['TradingGainsLosses', 'TradingAccountProfitLoss', 'SecuritiesGainLoss'],\n",
    "                'InvestmentBankingRevenue': ['InvestmentBankingRevenue', 'UnderwritingIncome'],\n",
    "                'TrustAndInvestmentFees': ['TrustFeesRevenue', 'InvestmentManagementAndTrustFees'],\n",
    "                'ServiceCharges': ['ServiceChargesOnDepositAccounts', 'ServiceCharges'],\n",
    "                'CardRevenue': ['CreditCardIncome', 'CreditCardFees'],\n",
    "                \n",
    "                # TIER 8: Regulatory & Capital Management\n",
    "                'CommonEquityTier1Ratio': ['CommonEquityTier1CapitalRatio', 'Tier1CommonCapitalRatio'],\n",
    "                'TotalCapitalRatio': ['TotalCapitalRatio', 'CapitalAdequacyTotalCapitalRatio'],\n",
    "                'RiskWeightedAssets': ['RiskWeightedAssets'],\n",
    "                'LeverageCapitalRatio': ['LeverageRatio', 'CapitalAdequacyLeverageRatio'],\n",
    "                'LiquidityRatio': ['LiquidityRatio', 'LiquidityCoverageRatio'],\n",
    "                \n",
    "                # TIER 9: Additional Balance Sheet Items\n",
    "                'TradingAssets': ['TradingSecuritiesDebt', 'TradingSecuritiesEquity', 'TradingSecurities'],\n",
    "                'AvailableForSaleSecurities': ['AvailableForSaleSecuritiesDebtSecurities', 'MarketableSecuritiesAvailableForSale'],\n",
    "                'HeldToMaturitySecurities': ['HeldToMaturitySecurities', 'DebtSecuritiesHeldToMaturity'],\n",
    "                'Goodwill': ['Goodwill'],\n",
    "                'IntangibleAssets': ['IntangibleAssetsNetExcludingGoodwill', 'FiniteLivedIntangibleAssetsNet']\n",
    "            }\n",
    "            \n",
    "            # Get all available periods\n",
    "            all_periods = set()\n",
    "            for metric_group in gaap_mapping.values():\n",
    "                for tag in metric_group:\n",
    "                    if tag in us_gaap:\n",
    "                        for unit_type in us_gaap[tag].get('units', {}):\n",
    "                            for entry in us_gaap[tag]['units'][unit_type]:\n",
    "                                if 'end' in entry and start_date <= entry['end'] <= end_date:\n",
    "                                    all_periods.add(entry['end'])\n",
    "            \n",
    "            # Extract data for each period\n",
    "            for period_end in sorted(all_periods):\n",
    "                period_data = {\n",
    "                    'Datetime': period_end,\n",
    "                    'CompanyName': company_facts.get('entityName', 'Unknown')\n",
    "                }\n",
    "                \n",
    "                # Extract each metric\n",
    "                for target_metric, possible_tags in gaap_mapping.items():\n",
    "                    value = None\n",
    "                    for tag in possible_tags:\n",
    "                        if tag in us_gaap:\n",
    "                            for unit_type in us_gaap[tag].get('units', {}):\n",
    "                                for entry in us_gaap[tag]['units'][unit_type]:\n",
    "                                    if entry.get('end') == period_end and 'val' in entry:\n",
    "                                        # Prefer quarterly data (form 10-Q) over annual, and recent over old\n",
    "                                        if entry.get('form') in ['10-Q', '10-K']:\n",
    "                                            if value is None or entry.get('form') == '10-Q':\n",
    "                                                value = entry['val']\n",
    "                                            break\n",
    "                                if value is not None:\n",
    "                                    break\n",
    "                        if value is not None:\n",
    "                            break\n",
    "                    \n",
    "                    period_data[target_metric] = value\n",
    "                \n",
    "                # Only add if we have some meaningful data (at least core metrics)\n",
    "                core_metrics = ['NetIncome', 'TotalRevenue', 'TotalAssets', 'ShareholdersEquity']\n",
    "                if any(period_data.get(metric) is not None for metric in core_metrics):\n",
    "                    metrics_data.append(period_data)\n",
    "        \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error extracting metrics: {str(e)}\")\n",
    "        \n",
    "        return metrics_data\n",
    "    \n",
    "    def calculate_derived_metrics(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Calculate derived financial metrics that can't be directly extracted\n",
    "        \n",
    "        Args:\n",
    "            df: DataFrame with base financial metrics\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame with additional calculated metrics\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Calculate ROE if not available (Net Income / Shareholders Equity)\n",
    "            mask = (df['ReturnOnEquity'].isna()) & (df['NetIncome'].notna()) & (df['ShareholdersEquity'].notna()) & (df['ShareholdersEquity'] != 0)\n",
    "            df.loc[mask, 'ReturnOnEquity'] = (df.loc[mask, 'NetIncome'] / df.loc[mask, 'ShareholdersEquity']) * 100\n",
    "            \n",
    "            # Calculate ROA if not available (Net Income / Total Assets)\n",
    "            mask = (df['ReturnOnAssets'].isna()) & (df['NetIncome'].notna()) & (df['TotalAssets'].notna()) & (df['TotalAssets'] != 0)\n",
    "            df.loc[mask, 'ReturnOnAssets'] = (df.loc[mask, 'NetIncome'] / df.loc[mask, 'TotalAssets']) * 100\n",
    "            \n",
    "            # Calculate Book Value Per Share if not available\n",
    "            mask = (df['BookValuePerShare'].isna()) & (df['ShareholdersEquity'].notna())\n",
    "            # Note: Would need shares outstanding data which may not be readily available\n",
    "            \n",
    "            # Calculate Efficiency Ratio if not available (Non-Interest Expense / (Net Interest Income + Non-Interest Income))\n",
    "            mask = (df['EfficiencyRatio'].isna()) & (df['NonInterestExpense'].notna()) & \\\n",
    "                   ((df['NetInterestIncome'].notna()) | (df['NonInterestIncome'].notna()))\n",
    "            \n",
    "            revenue_base = df['NetInterestIncome'].fillna(0) + df['NonInterestIncome'].fillna(0)\n",
    "            df.loc[mask & (revenue_base != 0), 'EfficiencyRatio'] = (df.loc[mask & (revenue_base != 0), 'NonInterestExpense'] / revenue_base.loc[mask & (revenue_base != 0)]) * 100\n",
    "            \n",
    "            # Calculate Net Interest Margin if not available\n",
    "            # This would require average earning assets data which may not be available\n",
    "            \n",
    "            logger.info(\"Calculated derived financial metrics\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error calculating derived metrics: {str(e)}\")\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def download_bank_data(self, start_date: str = \"2019-01-01\", end_date: str = \"2025-12-31\") -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Download earnings data for all banks\n",
    "        \n",
    "        Args:\n",
    "            start_date: Start date in YYYY-MM-DD format\n",
    "            end_date: End date in YYYY-MM-DD format\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame containing all bank earnings data\n",
    "        \"\"\"\n",
    "        all_data = []\n",
    "        \n",
    "        logger.info(f\"Starting data download for {len(self.top_banks)} banks from {start_date} to {end_date}\")\n",
    "        logger.info(f\"Extracting {len(self.target_metrics)} financial metrics\")\n",
    "        \n",
    "        for i, (bank_name, cik) in enumerate(self.top_banks.items()):\n",
    "            logger.info(f\"Processing {i+1}/{len(self.top_banks)}: {bank_name}\")\n",
    "            \n",
    "            try:\n",
    "                # Get company facts\n",
    "                company_facts = self.get_company_facts(cik)\n",
    "                if company_facts:\n",
    "                    # Extract metrics\n",
    "                    bank_metrics = self.extract_financial_metrics(company_facts, start_date, end_date)\n",
    "                    all_data.extend(bank_metrics)\n",
    "                    \n",
    "                    logger.info(f\"Extracted {len(bank_metrics)} records for {bank_name}\")\n",
    "                else:\n",
    "                    logger.warning(f\"No company facts found for {bank_name}\")\n",
    "                \n",
    "                # Rate limiting - SEC allows 10 requests per second\n",
    "                time.sleep(0.1)\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error processing {bank_name}: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        # Create DataFrame\n",
    "        df = pd.DataFrame(all_data)\n",
    "        \n",
    "        if not df.empty:\n",
    "            # Convert datetime column\n",
    "            df['Datetime'] = pd.to_datetime(df['Datetime'])\n",
    "            \n",
    "            # Ensure all target metrics are present as columns (even if empty)\n",
    "            for metric in self.target_metrics:\n",
    "                if metric not in df.columns:\n",
    "                    df[metric] = None\n",
    "            \n",
    "            # Reorder columns: Datetime, CompanyName, then metrics in priority order\n",
    "            column_order = ['Datetime', 'CompanyName'] + self.target_metrics\n",
    "            df = df.reindex(columns=column_order)\n",
    "            \n",
    "            # Calculate derived metrics\n",
    "            df = self.calculate_derived_metrics(df)\n",
    "            \n",
    "            # Sort by company and date\n",
    "            df = df.sort_values(['CompanyName', 'Datetime'])\n",
    "            \n",
    "            # Reset index\n",
    "            df = df.reset_index(drop=True)\n",
    "            \n",
    "            logger.info(f\"Successfully extracted {len(df)} total records with {len(self.target_metrics)} metrics\")\n",
    "        else:\n",
    "            logger.warning(\"No data was extracted\")\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def save_to_excel(self, df: pd.DataFrame, filename: str = \"bank_earnings_data.xlsx\"):\n",
    "        \"\"\"\n",
    "        Save DataFrame to Excel file with enhanced formatting\n",
    "        \n",
    "        Args:\n",
    "            df: DataFrame to save\n",
    "            filename: Output filename\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Create Excel writer\n",
    "            with pd.ExcelWriter(filename, engine='openpyxl') as writer:\n",
    "                # Main data sheet\n",
    "                df.to_excel(writer, sheet_name='Bank_Earnings_Data', index=False)\n",
    "                \n",
    "                # Summary sheet\n",
    "                if not df.empty:\n",
    "                    summary_data = []\n",
    "                    for company in df['CompanyName'].unique():\n",
    "                        company_data = df[df['CompanyName'] == company]\n",
    "                        latest_data = company_data.iloc[-1] if len(company_data) > 0 else None\n",
    "                        \n",
    "                        summary_data.append({\n",
    "                            'Company': company,\n",
    "                            'Records': len(company_data),\n",
    "                            'Date_Range': f\"{company_data['Datetime'].min().strftime('%Y-%m-%d')} to {company_data['Datetime'].max().strftime('%Y-%m-%d')}\",\n",
    "                            'Latest_Total_Assets': latest_data['TotalAssets'] if latest_data is not None else None,\n",
    "                            'Latest_Net_Income': latest_data['NetIncome'] if latest_data is not None else None,\n",
    "                            'Latest_ROE': latest_data['ReturnOnEquity'] if latest_data is not None else None,\n",
    "                            'Latest_ROA': latest_data['ReturnOnAssets'] if latest_data is not None else None,\n",
    "                            'Data_Quality_Score': f\"{(company_data[self.target_metrics].notna().sum().sum() / (len(company_data) * len(self.target_metrics)) * 100):.1f}%\"\n",
    "                        })\n",
    "                    \n",
    "                    summary_df = pd.DataFrame(summary_data)\n",
    "                    summary_df.to_excel(writer, sheet_name='Summary', index=False)\n",
    "                \n",
    "                # Metrics Dictionary sheet\n",
    "                metrics_info = []\n",
    "                tier_descriptions = {\n",
    "                    'TIER 1': 'Core Profitability & Performance - Most critical metrics for stakeholder decision making',\n",
    "                    'TIER 2': 'Capital & Balance Sheet Strength - Financial stability and scale indicators',\n",
    "                    'TIER 3': 'Risk Management & Credit Quality - Credit risk and asset quality measures',\n",
    "                    'TIER 4': 'Income Statement Detail - Detailed revenue and expense components',\n",
    "                    'TIER 5': 'Operational Efficiency - Cost management and operational performance',\n",
    "                    'TIER 6': 'Growth & Market Metrics - Growth rates and market position indicators',\n",
    "                    'TIER 7': 'Trading & Investment Banking - Specialized revenue streams',\n",
    "                    'TIER 8': 'Regulatory & Capital Management - Regulatory compliance metrics',\n",
    "                    'TIER 9': 'Additional Balance Sheet Items - Supporting balance sheet components'\n",
    "                }\n",
    "                \n",
    "                current_tier = None\n",
    "                tier_counters = {'TIER 1': 0, 'TIER 2': 0, 'TIER 3': 0, 'TIER 4': 0, 'TIER 5': 0, \n",
    "                               'TIER 6': 0, 'TIER 7': 0, 'TIER 8': 0, 'TIER 9': 0}\n",
    "                \n",
    "                for i, metric in enumerate(self.target_metrics):\n",
    "                    # Determine tier based on position\n",
    "                    if i < 7: tier = 'TIER 1'\n",
    "                    elif i < 15: tier = 'TIER 2'\n",
    "                    elif i < 21: tier = 'TIER 3'\n",
    "                    elif i < 28: tier = 'TIER 4'\n",
    "                    elif i < 33: tier = 'TIER 5'\n",
    "                    elif i < 38: tier = 'TIER 6'\n",
    "                    elif i < 43: tier = 'TIER 7'\n",
    "                    elif i < 48: tier = 'TIER 8'\n",
    "                    else: tier = 'TIER 9'\n",
    "                    \n",
    "                    tier_counters[tier] += 1\n",
    "                    \n",
    "                    metrics_info.append({\n",
    "                        'Metric_Name': metric,\n",
    "                        'Priority_Rank': i + 1,\n",
    "                        'Tier': tier,\n",
    "                        'Tier_Description': tier_descriptions[tier],\n",
    "                        'Column_Position': i + 3  # +3 for Datetime and CompanyName columns\n",
    "                    })\n",
    "                \n",
    "                metrics_df = pd.DataFrame(metrics_info)\n",
    "                metrics_df.to_excel(writer, sheet_name='Metrics_Dictionary', index=False)\n",
    "            \n",
    "            logger.info(f\"Data saved to {filename}\")\n",
    "            logger.info(f\"Excel file contains 3 sheets: Bank_Earnings_Data, Summary, and Metrics_Dictionary\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error saving to Excel: {str(e)}\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to run the SEC bank data extraction\n",
    "    \"\"\"\n",
    "    # Initialize extractor\n",
    "    # IMPORTANT: Replace with your actual contact information\n",
    "    extractor = SECBankDataExtractor(user_agent=\"YourCompany yourname@yourcompany.com\")\n",
    "    \n",
    "    # Set date range (default 2019-2025)\n",
    "    start_date = \"2019-01-01\"\n",
    "    end_date = \"2025-12-31\"\n",
    "    \n",
    "    print(f\"SEC Bank Earnings Data Extractor - Enhanced Version\")\n",
    "    print(f\"==================================================\")\n",
    "    print(f\"Downloading data from {start_date} to {end_date}\")\n",
    "    print(f\"Target banks: {len(extractor.top_banks)}\")\n",
    "    print(f\"Target metrics: {len(extractor.target_metrics)} (prioritized by stakeholder importance)\")\n",
    "    print()\n",
    "    \n",
    "    # Display metric tiers\n",
    "    print(\"Metric Priority Tiers:\")\n",
    "    print(\"TIER 1 (1-7): Core Profitability & Performance\")\n",
    "    print(\"TIER 2 (8-15): Capital & Balance Sheet Strength\") \n",
    "    print(\"TIER 3 (16-21): Risk Management & Credit Quality\")\n",
    "    print(\"TIER 4 (22-28): Income Statement Detail\")\n",
    "    print(\"TIER 5 (29-33): Operational Efficiency\")\n",
    "    print(\"TIER 6 (34-38): Growth & Market Metrics\")\n",
    "    print(\"TIER 7 (39-43): Trading & Investment Banking\")\n",
    "    print(\"TIER 8 (44-48): Regulatory & Capital Management\")\n",
    "    print(\"TIER 9 (49-50): Additional Balance Sheet Items\")\n",
    "    print()\n",
    "    \n",
    "    # Download data\n",
    "    df = extractor.download_bank_data(start_date, end_date)\n",
    "    \n",
    "    if not df.empty:\n",
    "        print(f\"\\nData extraction completed!\")\n",
    "        print(f\"Total records: {len(df)}\")\n",
    "        print(f\"Companies with data: {df['CompanyName'].nunique()}\")\n",
    "        print(f\"Date range: {df['Datetime'].min()} to {df['Datetime'].max()}\")\n",
    "        \n",
    "        # Save to Excel\n",
    "        output_filename = f\"bank_earnings_data_{start_date}_{end_date}.xlsx\"\n",
    "        extractor.save_to_excel(df, output_filename)\n",
    "        \n",
    "        print(f\"\\nData saved to: {output_filename}\")\n",
    "        \n",
    "        # Display data quality metrics\n",
    "        total_possible_values = len(df) * len(extractor.target_metrics)\n",
    "        actual_values = df[extractor.target_metrics].notna().sum().sum()\n",
    "        data_completeness = (actual_values / total_possible_values) * 100\n",
    "        \n",
    "        print(f\"\\nData Quality Summary:\")\n",
    "        print(f\"Data completeness: {data_completeness:.1f}%\")\n",
    "        print(f\"Total possible data points: {total_possible_values:,}\")\n",
    "        print(f\"Actual data points extracted: {actual_values:,}\")\n",
    "        \n",
    "        # Show top metrics by data availability\n",
    "        print(f\"\\nTop 10 metrics by data availability:\")\n",
    "        metric_availability = df[extractor.target_metrics].notna().sum().sort_values(ascending=False)\n",
    "        for i, (metric, count) in enumerate(metric_availability.head(10).items()):\n",
    "            percentage = (count / len(df)) * 100\n",
    "            print(f\"{i+1:2d}. {metric:<25} {count:4d} records ({percentage:5.1f}%)\")\n",
    "        \n",
    "        # Display sample data for most important metrics\n",
    "        important_columns = ['Datetime', 'CompanyName'] + extractor.target_metrics[:10]\n",
    "        print(f\"\\nSample data preview (Top 10 priority metrics):\")\n",
    "        print(df[important_columns].head(3).to_string(index=False))\n",
    "        \n",
    "        # Show metrics by tier\n",
    "        print(f\"\\nMetrics organized by priority tiers:\")\n",
    "        tier_ranges = [\n",
    "            (1, 7, \"TIER 1: Core Profitability & Performance\"),\n",
    "            (8, 15, \"TIER 2: Capital & Balance Sheet Strength\"),\n",
    "            (16, 21, \"TIER 3: Risk Management & Credit Quality\"),\n",
    "            (22, 28, \"TIER 4: Income Statement Detail\"),\n",
    "            (29, 33, \"TIER 5: Operational Efficiency\"),\n",
    "            (34, 38, \"TIER 6: Growth & Market Metrics\"),\n",
    "            (39, 43, \"TIER 7: Trading & Investment Banking\"),\n",
    "            (44, 48, \"TIER 8: Regulatory & Capital Management\"),\n",
    "            (49, 50, \"TIER 9: Additional Balance Sheet Items\")\n",
    "        ]\n",
    "        \n",
    "        for start_idx, end_idx, tier_name in tier_ranges:\n",
    "            print(f\"\\n{tier_name}:\")\n",
    "            tier_metrics = extractor.target_metrics[start_idx-1:end_idx]\n",
    "            for i, metric in enumerate(tier_metrics, start_idx):\n",
    "                availability = df[metric].notna().sum()\n",
    "                percentage = (availability / len(df)) * 100 if len(df) > 0 else 0\n",
    "                print(f\"  {i:2d}. {metric:<30} ({availability:3d} records, {percentage:5.1f}%)\")\n",
    "        \n",
    "    else:\n",
    "        print(\"No data was extracted. Please check the logs for errors.\")\n",
    "        print(\"\\nTroubleshooting suggestions:\")\n",
    "        print(\"1. Verify your User-Agent contains valid company name and email\")\n",
    "        print(\"2. Check your internet connection\")\n",
    "        print(\"3. Ensure the date range contains valid reporting periods\")\n",
    "        print(\"4. Review the logs above for specific error messages\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13d68c7-1a1d-45e8-b674-1542a99c141e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
